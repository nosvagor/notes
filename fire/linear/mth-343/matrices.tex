\chapter{1 Matrices and Gaussian Elimination}

% chktex-file 1
% chktex-file 3
% chktex-file 21
% chktex-file 36
% chktex-file 27

\section{1.2 The Geometry of Linear Equations}
\begin{itemize}
  \item []

  \subsection{Problems 1--12}
  \begin{enumerate}\color{foreground-2}
    \item For the equations \( x + y = 4, ~ 2x - 2y = 4 \), draw the row picture (two
      intersecting lines) and the column picture (combination of two columns
      equal to the column vector (4,4) on the right side).

      \begin{figure}[ht]
          \centering
          \incfig[1]{1.2.1}
          \caption{1.2.1}
      \end{figure}

    \item Solve to find a combination of the columns that equals \(b\):
      \begin{align*}
        u - v - w &= b_1 \\
        v + w &= b_2 \\
        w &= b_3
      \end{align*}
      \vspace{-35pt}
      \fg{\begin{align*}
        &\then w = b_3 \\
        &\then v = b_2 - b_3 \\
        &\then u = b_1 + v + w = b_1 + b_2
      \end{align*}}
      \vspace{-18pt}

    \item Describe the intersection of the three planes \(  u+v+w+z = 6 \) and
      \( u+w+z = 4 \) and \( u+w = 2 \) (all in four-dimensional space). Is it
      a line or a point or an empty set? What is the intersection if the fourth
      plane \( u = -1 \) is included? Find a fourth equation that leaves us
      with no solution.
      \begin{itemize}\color{foreground}
        \item \aset{A line}; \maybe{as \( u + w = 2 \) is only a line}. A fourth plane
          with \( u = -1 \) would produce a normally intersecting point. Any
          addition equation when \( u + w \neq 2 \) would produce an
          inconsistent equation.
      \end{itemize}

    \item Sketch these three lines and decide if the equations are solvable:
      \begin{align*}
        x + 2y &= 2 \\
        x - y &= 2 \\
        y &= 1
      \end{align*}
      \vspace{-30pt}
      \begin{figure}[h]
        \centering
        \incfig[1]{1.2.4}
        \caption{1.2.4}
      \end{figure}

      \aset{Inconsistent; multiple points of intersect}

      What happens if all right-hand sides are zero? Is there any nonzero
      choice of right-hand sides that allows the three lines to intersect at
      the same point?
      \begin{itemize}\color{foreground}
        \item If all the solutions were zero, then it would be a trivial
          solution.
        \item Yes, e.g., \( x - y = -1 \) would produce a single point of
          intersection.
      \end{itemize}

    \item Find two points on the line of intersection of the three planes \( t
      = 0 \) and \( z = 0 \) and \( x+y+z+t = 1 \) in four-dimensional space.

     \fg{\[
        \begin{bmatrix} 1 \\ 0 \\ 0 \\ 0 \end{bmatrix} \qquad
        \begin{bmatrix} 0 \\ 1 \\ 0 \\ 0  \end{bmatrix}
     \]}

    \item When \( b = (2,5,7) \), find a solution \( (u,v,w) \) to equation (4)
      different from the solution \( (1,0,1) \) mentioned in the text.
      \begin{itemize}\color{foreground}
        \item Since there are infinite solutions, and if \tbm{s} vector
          describing one solution and \( \lambda \) is any scalar, then \(
          \bm{s} \lambda \) is also a solution. E.g., \( \left( 1,0,1 \right)
          42 = \left( 42,0,42 \right)  \)
      \end{itemize}
      \vspace{30pt}
      \addtocounter{enumi}{1}
      \item Explain why the system
      \begin{align*}
        u + v + w &= 2 \\
        u + 2v + 3w &= 1 \\
        v + 2w &= 0
      \end{align*}
      is singular by finding a combination of the three equations that adds up
      to \(0 = 1\). What value should replace the last zero on the right side to
      allow the equations to have solutions---and what is one of the solutions?
      \fg{\begin{align*}
      \begin{bmatrix}[ccc|c]
        1 & 1 & 1 & 2 \\
        1 & 2 & 3 & 1 \\
        0 & 1 & 2 & 0
      \end{bmatrix}
      \xRightarrow{R_2 - R_1}
      \begin{bmatrix}[ccc|c]
        1 & 1 & 1 & 2 \\
        0 & 1 & 2 & -1 \\
        0 & 1 & 2 & 0
      \end{bmatrix}
      \xRightarrow{R_3-R_2}
      \begin{bmatrix}[ccc|c]
        1 & 1 & 1 & 2 \\
        0 & 1 & 2 & -1 \\
        0 & 0 & 0 & 1
      \end{bmatrix}
      \end{align*}}
      \begin{itemize}\color{foreground}
        \item Replacing the last zero with \aset{\( -1 \)} would yield infinite
          solutions. One solution would be \( \left[ 3,-1,0 \right]^T \)
      \end{itemize}

    \item The column picture for the previous exercise (singular system) is
      \begin{align*}
        u \begin{bmatrix} 1 \\ 1 \\ 0 \end{bmatrix} +
        v \begin{bmatrix} 1 \\ 2 \\ 1 \end{bmatrix} +
        w \begin{bmatrix} 1 \\ 3 \\ 2 \end{bmatrix} = b
      \end{align*}
      Show that the three columns on the left lie in the same plane by
      expressing the third as a combination of the first two. What are all the
      solutions \( (u,v,w) \) if \(b\) is the zero vector \( (0,0,0) \)?
      \fg{\begin{align*}
        -1 \begin{bmatrix} 1 \\ 1 \\ 0 \end{bmatrix} +
        2 \begin{bmatrix} 1 \\ 2 \\ 1 \end{bmatrix} =
        \begin{bmatrix} 1 \\ 3 \\ 2 \end{bmatrix}
      \end{align*}}
      \begin{itemize}\color{foreground}
        \item If is \tbm{b} equal to the zero vector \nil then the solutions
          \maybe{are equal to the kernel} i.e., \( -1x_1, 2x_2, 0x_3  = \nil\)
      \end{itemize}

    \item Under what condition on \( y_1, y_2, y_3 \) do the points \((0,y_1),
      (1,y_2), (2,y_3)\) lie on a straight line?
      \begin{itemize}\color{foreground}
        \item Question 9 describes the state at which they are collinear, i.e.,
          \( y_3 = 2y_2 - y_1 \)
      \end{itemize}


    \item These equations are certain to have the solution \( x = y = 0 \). For which
      values of \(a\) is there a whole line of solutions?
      \begin{align*}
        ax + 2y = 0 \\
        2x + ay = 0
      \end{align*}
      \begin{itemize}\color{foreground}
        \item Only the scalars that make the lines linearly dependent, i.e., \(
          \aset{a = 2, -2} \)
      \end{itemize}

  \end{enumerate}

  \subsection{Problems 17--23}
  \begin{enumerate}[resume]\color{foreground-2}
    \addtocounter{enumi}{5}
    \item The first of these equations plus the second equals the third:
      \begin{align*}
        x + y + z &= 2 \\
        x + 2y + z &= 3 \\
        2x + 3y + 2z &= 5
      \end{align*}

      The first two planes meet along a line. The third plane contains that
      line, because if \( x, y, z \) satisfy the first two equations then they
      also \aset{span all of \( \R^3 \)}. The equations have infinitely many solutions (the whole line \tbm{L}). Find
      three solutions.
      \begin{itemize}\color{foreground}
        \item \( \bm{v} = (4,4,0), \bm{w} = (6,3,2), \bm{u} = 2v + -1w\)
      \end{itemize}

    \item Move the third plane in Problem 17 to a parallel plane \( 2x + 3y + 2z =
      9 \). Now the three equations have no solution---\textit{why not}? The first two planes
      meet along the line \tbm{L}, but the third plane doesn't that
      \aset{cross} that line.

    \item In Problem 17 the columns are \( (1,1,2) \) and \( (1,2,3) \) and \(
      (1,1,2) \). This is a ``singular case'' because the third column is
      \aset{linearly dependent} Find two combinations of the columns that give
      \( b = (2,3,5) \). This is only possible for \( b = (4,6,c) \) if \(c = \aset{10}\)

    \item Normally 4 ``planes'' in four-dimensional space meet at a \aset{tensor}. Normally 4
      column vectors in four-dimensional space can combine to produce \(b\). What
      combination of \( (1,0,0,0), (1,1,0,0), (1,1,1,0), (1,1,1,1) \) produces \(b =
      (3,3,3,2)\)? \maybe{\((1,0,0,-2)\)} What 4 equations for \(x, y, z, t\)
      are you solving? \aset{A lower triangular matrix, i.e.,}
      \fg{\[
        \begin{bmatrix}[cccc|c]
          1 & 0 & 0 & 0 & 3 \\
          1 & 1 & 0 & 0 & 3 \\
          1 & 1 & 1 & 0 & 3 \\
          1 & 1 & 1 & 1 & 1
        \end{bmatrix}
      \]}

    \item When equation 1 is added to equation 2, which of these are changed:
      the planes in the row picture, the column picture, the coefficient
      matrix, the solution?
      \begin{itemize}\color{foreground}
        \item Row operations do not change the solution. Row 2 is changed, thus
          the second plane is changed. \maybe{All columns are changed.}
      \end{itemize}

      \newpage
    \item  If \((a,b)\) is a multiple of \((c,d)\) with \(abcd \neq 0\), show
      that \((a,c)\) is a multiple of \((b,d)\). This is surprisingly
      important: call it a challenge question. You could use numbers first to
      see how \(a, b, c\), and \(d\) are related. The question will lead to:

      If \(A = \begin{bsmallmatrix*} a && b \\ c && d\end{bsmallmatrix*}\)  has
      dependent rows then it has dependent columns.

      \vspace{25pt}
      \src{
        \link{https://www.math.colostate.edu/~clayton/teaching/m215s10/homework/hw1solutions.pdf}{Received
        help from this document (pg. 3), accessed 10/01/2021}
      }
      \fg{\begin{align*}
          \lambda \in \R, &\quad (a,b) = \lambda(c,d) = ( \lambda c, \lambda d) \\
        &\then a = \lambda c = \lambda c d^{-1} d = d^{-1} c\lambda d = d^{-1}c b \\
        &\then \left( a,c \right) = \left( d^{-1} c b, d^{-1}d c \right) = cd^{-1}(b,d)
      \end{align*}}
      \fg{Thus, \( (b,d) \) is a multiple of  \( (a,c) \)}

      \item In these equations, the third column (multiplying w) is the same as
        the right side \(b\). The column form of the equations immediately
        gives what solution for \((u,v,w)\)?
        \begin{align*}
          6u + 7v + 8w &= 8 \\
          4u + 5v + 9w &= 9 \\
          2u - 2v + 7w &= 7
        \end{align*}
        \begin{itemize}\color{foreground}
          \item First two columns are irrelevant, \( u = 0, v = 0 \), only need \( \aset{w} \)
        \end{itemize}

  \end{enumerate}
\end{itemize}

\section{1.3 Gaussian Elimination}
\begin{itemize}
  \item []

  \subsection{Problems 6, 7}
  \begin{enumerate}
    \minor{\item[6.] Choose a coefficient \(b\) that makes this system singular. Then choose a
    right-hand side \(g\) that makes it solvable. Find two solutions in that
    singular case}.
    \minor{\begin{align*}
        2x + by &= 16  \\
        4x + 8y &= g
    \end{align*}}
    \vspace{-30pt}
    \begin{align*}
      2x + \aset{4y} &= 16  \\
      4x + 8y &= \aset{32}
    \end{align*}
    \begin{itemize}
      \item Since \( R_2 \) is just a multiple of \( R_1 \), then solving for
        \( x,y \), with one variable = 0, in the first equation will yield two
        solutions, i.e., \( (8,0), (0,4) \)
    \end{itemize}


    \minor{\item[7.] For which numbers a does elimination break down (a)
        permanently, and (b) temporarily?
        \begin{align*}
          ax + 3y &= -3 \\
          4x + 6y &= 6
        \end{align*}

      Solve for \(x\) and \(y\) after fixing the second breakdown by a row
    exchange.}
    \begin{itemize}
      \item Permanently: \( \aset{a = 2} \) (linearly dependent, no solution)
      \item Temporarily: \( \aset{a = 0} \);
        \begin{align*}
          \begin{bmatrix}[cc|c]
          4 & 6 & 6  \\
          0 & 3 & -3
          \end{bmatrix} \rightarrow
          \begin{bmatrix}[cc|c]
          1 & 0 & 3  \\
          0 & 1 & -1
          \end{bmatrix} \\
          y = -1, \quad x = 3
        \end{align*}
    \end{itemize}

  \end{enumerate}

 \subsection{Problems 17, 18, 19}
 \begin{enumerate}\setcounter{enumi}{16}
   \minor{\item Which number \(q\) makes this system singular and which right-hand
     side t gives it infinitely many solutions? Find the solution that has \(z =
     1\).
     \begin{align*}
       x + 4y - 2z &= 1 \\
       x + 7y - 6z &= 6 \\
       3y + qz &= t
     \end{align*}}
    \vspace{-25pt}
     \begin{align*}
       x + 4y - 2z &= 1 \\
       x + 7y - 6z &= 6 \\
       3y + \aset{-4}z &= \aset{5}
     \end{align*}
     \begin{itemize}
       \item If \( q = -4\), then \( R_3 \) would have no pivot
       \item If \( t = 5 \), then there would be finite solutions, \( R_3 \)
         would be linearly dependent with \( R_2 \)
     \end{itemize}


    \minor{\item It is impossible for a system of linear equations to have
      exactly two solutions. Explain why.
      \begin{itemize}
      \item If \( (x,y,z) \) and \( \left( X,Y,Z \right) \) are two
        solutions, what is the other one?
        \begin{itemize}\color{foreground}
          \item There is no other \textit{one}, there would be infinitely
            many.
        \end{itemize}
      \item If 25 planes meet at two points, where else do they meet?
        \begin{itemize}\color{foreground}
          \item Every other single point, they would span all of \( \R^3 \)
        \end{itemize}

  \end{itemize}}

\minor{\item Three planes can fail to have an intersection point, when no two
  planes are parallel. The system is singular if row 3 of \tbm{A} is a
  \aset{linearly dependent; a combination} of the first two rows. Find a third equation that canâ€™t be
solved if \(x+y+z = 0\) and \(x-2y-z = 1\).}
  \begin{align*}
    x + y + z = 0 \\
    x - 2y - z = 1 \\
    R_1 + R_2 \neq 1 \rightarrow ~\text{parallel; no solution, e.g.,} \\
    \aset{2x - y = 42}
  \end{align*}

\end{enumerate}

\subsection{Problems 30, 31}
 \begin{enumerate}\setcounter{enumi}{29}
   \minor{\item Use elimination to solve
     \begin{align*}
       u + v + w &= 6 &&& u + v + w &= 7 \\
       u + 2v + 2w &= 11 &&\text{and}& u + 2v + 2w &= 10 \\
       2u + 3v - 4w &= 3 &&& 2u + 3v - 4w &= 3
   \end{align*}}
   \vspace{-20pt}
   \begin{align*}
     \rref{\begin{bmatrix}[ccc|c]
     1 & 1 & 1 & 6 \\
     1 & 2 & 2 & 11 \\
     2 & 3 & -4 & 3
    \end{bmatrix}} \rightarrow
    \begin{bmatrix}[ccc|c]
    1 & 0 & 0 & 1  \\
    0 & 1 & 0 & 3 \\
    0 & 0 & 1 & 2
    \end{bmatrix}\\
     \rref{\begin{bmatrix}[ccc|c]
     1 & 1 & 1 & 7 \\
     1 & 2 & 2 & 10 \\
     2 & 3 & -4 & 3
    \end{bmatrix}} \rightarrow
    \begin{bmatrix}[ccc|c]
    1 & 0 & 0 & 4  \\
    0 & 1 & 0 & 1 \\
    0 & 0 & 1 & 2
    \end{bmatrix}
   \end{align*}

   \minor{\item For which three numbers \(a\) will elimination fail to give three
     pivots?
     \begin{align*}
       ax + 2y + 3z &= b_1 \\
       ax + ay + 4z &= b_2 \\
       ax + ay + az &= b_3
   \end{align*}}
   \vspace{-20pt}
   \begin{itemize}
     \item For \( a = 0 \), multiple failures.
     \item For \( a = 2 \), columns \( 0,1 \) would be equal.
     \item For \( a = 4 \), rows \( 1,2 \) would be equal.
   \end{itemize}

 \end{enumerate}

\end{itemize}

\section{1.4 Matrix Notation and Matrix Multiplication}
\begin{itemize}
  \item []

    \subsection{Problems 4, 10, 17, 19}
    \begin{itemize}
      \minor{\item[4.] If an \(m \times n\) matrix \tbm{A} multiplies an
      \(n\)-dimensional vector \tbm{x}, how many separate multiplications are
      involved? What if A multiplies an \(n \times p\) matrix \tbm{B}?}
      \begin{itemize}
        \item \aset{\( m\cdot n \)} multiplications; number of rows times the
          length of \tbm{x}.
        \item \aset{\( m \cdot n \cdot p \)}; same as above, except accounting
          for each additional column \( p \).
      \end{itemize}


    \minor{\item[10.] True or false? Give a specific counterexample when false.
      \begin{itemize}
        \item If rows 1 and 3 of \tbm{B} are the same, so are rows 1 and 3 of \tbm{AB}.
          \begin{itemize}\color{foreground}
            \item \false{false}; matrix multiplication is done by the rows of
              the left matrix and the columns of the right, the rows may be the
              same, but if a column between the two are different, then there
              would be different multiplications occurring, e.g.,
              \begin{align*}
                \begin{bmatrix}
                1 & 2 & 3 \\
                4 & 5 & 6 \\
                7 & 8 & 9
                \end{bmatrix}
                \begin{bmatrix}
                1 & 1 & 1 \\
                4 & 2 & 0 \\
                1 & 1 & 1
                \end{bmatrix} =
                \begin{bmatrix}
                12 & 8 & 4 \\
                30 & 20 & 10  \\
                38 & 32 & 16
                \end{bmatrix}
              \end{align*}
         \end{itemize}

        \item If columns 1 and 3 of \tbm{B} are the same, so are columns 1 and 3 of \tbm{AB}.
          \begin{itemize}
            \item \true{true};
          \end{itemize}

        \item If rows 1 and 3 of \tbm{A} are the same, so are rows 1 and 3 of \tbm{AB}.
          \begin{itemize}
            \item \true{true}
          \end{itemize}

        \item \((AB)^2 = A^2B^2\).
          \begin{itemize}\color{foreground}
            \item \false{false} (most of the time), e.g.,
              \begin{align*}
                \bm{A} &=\begin{bmatrix}
                1 & 2 & 3 \\
                4 & 5 & 6 \\
                7 & 8 & 9
                \end{bmatrix}
                \bm{B} = \begin{bmatrix}
                1 & 1 & 1 \\
                4 & 2 & 0 \\
                1 & 1 & 1
                \end{bmatrix} \\
                  \bm{AB}^2 =
                \begin{bmatrix}
                144 & 64 & 16 \\
                900 & 400 & 100 \\
                2304 & 1024 & 256
                \end{bmatrix}
                       &\neq
                \begin{bmatrix}
                74 & 26 & 10 \\
                452 & 152 & 52 \\
                1154 & 386 & 130
                \end{bmatrix} =
               \bm{A}^2 \bm{B}^2
              \end{align*}
          \end{itemize}

    \end{itemize}}

    \minor{\item[17.] Which of the following matrices are guaranteed to equal \((A+B)^2\)?
      \begin{align*}
      A^2 + 2AB+B^2, \\
      \text{\true{\(A(A+B) + B(A+B)\)}} \\
      \text{\true{\((A+B)(B+A)\)}}, \\
      \text{\true{\(A^2+AB+BA+B^2\)}}
  \end{align*}}
  \newpage
    \minor{\item[19.] A fourth way to multiply matrices is columns of \tbm{A} times rows
      of \tbm{B}:

      \tbm{AB}\( = \text{(column 1)(row 1)}+\cdots+\text{(column n)(row n)} =\)
      sum of simple matrices.

      Give a \(2\times 2\) example of this important rule for matrix multiplication.}
      \begin{align*}
      \begin{bmatrix}
      1 & 2 \\
      3 & 4
      \end{bmatrix}
      \begin{bmatrix}
      a & b \\
      c & d
      \end{bmatrix} =
      \left(
        a \begin{bmatrix} 1 \\ 3 \end{bmatrix} +
        c \begin{bmatrix} 2 \\ 4 \end{bmatrix}
        b \begin{bmatrix} 1 \\ 3 \end{bmatrix} +
        d \begin{bmatrix} 2 \\ 4 \end{bmatrix}
      \right)
      \end{align*}
      Useful, as the right matrix can be thought of as the \aset{weights that
      scale} the elements of the columns of the left matrix.


    \end{itemize}

    \subsection{Problems 30--31}
    \minor{\begin{enumerate}\setcounter{enumi}{29}
      \item Multiply these matrices:
        \[
      \begin{bmatrix}
      0 & 0 & 1 \\
      0 & 1 & 0 \\
      1 & 0 & 0
      \end{bmatrix}
      \begin{bmatrix}
      1 & 2 & 3 \\
      4 & 5 & 6 \\
      7 & 8 & 9
      \end{bmatrix}
      \begin{bmatrix}
      0 & 0 & 1 \\
      0 & 1 & 0 \\
      1 & 0 & 0
      \end{bmatrix}\quad\text{and}\quad
      \begin{bmatrix}
      1 & 0 & 0 \\
      -1 & 1 & 0 \\
      -1 & 0 & 1
      \end{bmatrix}
      \begin{bmatrix}
      1 & 2 & 3 \\
      1 & 3 & 1 \\
      1 & 4 & 0
      \end{bmatrix}.
        \]
      \begin{align*}\color{foreground}
      \begin{bmatrix}
        9 & 8 & 7 \\
        6 & 5 & 4 \\
        3 & 2 & 1
      \end{bmatrix}\quad\text{and}\quad
      \begin{bmatrix}
      1 & 2 & 3 \\
      0 & 1 & -2 \\
      0 & 2 & -3
      \end{bmatrix}\quad\text{respectively}
      \end{align*}
      \begin{itemize}\color{foreground}
        \item The former multiplication performs two operations (left: swaps
          top and bottom columns, right: swaps left and right columns), while
          the latter subtracts row 1 from both row 2 and row 3.
      \end{itemize}

      \item This \(4\times 4 \) matrix needs which elimination matrices \(
        \bm{E}_{21} \) and \( \bm{E}_{32} \) and \(\bm{E}_{43} \)?
       \[
        \bm{A} = \begin{bmatrix}
          2 & -1 & 0 & 0 \\
          -1  & 2 & -1 & 0 \\
          0 & -1 & 2 & -1 \\
          0 & 0 & -1 & 2
        \end{bmatrix}
        \]
        \begin{itemize}\color{foreground}
          \item \( e_{21} = -\frac{1}{2}, \quad e_{32} = -\frac{2}{3}, \quad
            e_{43} = -\frac{3}{4} \)
          \item I suspect the factions will tend towards \( -1 \) if the matrix
            was expanded upon in a similar fusion?
        \end{itemize}

    \end{enumerate}}
    \vspace{16pt}

    \subsection{Problems 34, 35, 38, 42}
    \minor{\begin{enumerate}
        \item[34.] Multiply these matrices in the orders \tbm{FE} and \tbm{FE}
          and \(\bm{E}^2\):
          \begin{align*}
            \bm{E} = \begin{bmatrix}
            1 & 0 & 0  \\
            a & 1 & 0 \\
            b & 0 & 1
            \end{bmatrix} \qquad
            \bm{F} =
            \begin{bmatrix}
            1 & 0 & 0 \\
            0 & 1 & 0 \\
            0 & c & 1
            \end{bmatrix}
          \end{align*}
          \fg{\begin{align*}
           \bm{FE} =
           \begin{bmatrix}
           1 & 0 & 0 \\
           a & 1 & 0 \\
           ac+b & c & 1
           \end{bmatrix}\quad
           \bm{EF} =
           \begin{bmatrix}
           1 & 0 & 0 \\
           a & 1 & 0 \\
           b & c & 1
           \end{bmatrix}\quad
           \bm{E}^2 =
           \begin{bmatrix}
           1 & 0 & 0 \\
           2a & 1 & 0 \\
           2b & 0 & 1
           \end{bmatrix}\quad
          \end{align*}}

        \item[35.] \( \downarrow \)
        \begin{enumerate}
          \item Suppose all columns of \tbm{B} are the same. Then all columns of \tbm{EB}
            are the same, because each one is \tbm{E} times \aset{\tbm{B_{1n}}}.

          \item Suppose all rows of \tbm{B} are \([1~2~4]\). Show by example that all
            rows of \tbm{EB} are not \( [1~2~4] \). It is true that those rows
            are \aset{multiples of \( [1~2~4] \)}
            \begin{itemize}\color{foreground}
              \item E.g., if \( e_{12} = 2 \), then \( m_2 \) of \tbm{EB} would
                be \( [3~6~12] \)
            \end{itemize}

        \end{enumerate}

      \item[38.] If \tbm{AB} = \tbm{I} and \tbm{BC} = \tbm{I}, use the
        associative law to prove \(\bm{A} = \bm{C}\).
        \fg{\begin{align*}
            \bm{A} &= \bm{A}(\bm{BC}) \\
            \bm{A} &= (\bm{AB})\bm{C} \\
            \bm{A} &= \bm{C}
        \end{align*}}
        \vspace{-24pt}

      \item[42.] True of false?
        \begin{enumerate}
          \item If \( \bm{A}^2 \) is defined then A is necessarily square.
            \begin{itemize}\color{foreground}
              \item \true{true}; inner dimensions much match, i.e.,
                dimensions of \( n_1 = m_2 \). Thus, \tbm{A} must be square.
            \end{itemize}

          \item If \tbm{AB} and \tbm{BA} are defined, then \tbm{A} and \tbm{B}
            are square.
            \begin{itemize}\color{foreground}
              \item \false{false}; if \(\bm{A} = 6 \times 9 \) and \( \bm{B} =
                9 \times 6 \) allows for valid pre- and post-multiplication of
                \tbm{B}.
            \end{itemize}


          \item If \tbm{AB} and \tbm{BA} are defined, then \tbm{AB} and
            \tbm{BA} are square.
            \begin{itemize}\color{foreground}
              \item \true{true}; see above example, each case will still yield
                square matrices. Not a proof, but I can't see another way to
                falsify (b).
            \end{itemize}

          \item If \tbm{AB} = \tbm{B} then \( \bm{A} = \bm{I} \)
            \begin{itemize}\color{foreground}
              \item \false{false}; e.g.,\( \bm{B} = \nil \)
            \end{itemize}

        \end{enumerate}
    \end{enumerate}}

\end{itemize}

\section{1.5 Triangular Factors and Row Exchanges}
\begin{itemize}
  \item []

    \subsection{Problems 1, 6, 7, 14, 18}
    \begin{itemize}\color{foreground-2}
      \item[1.] When is an upper triangular matrix nonsingular (a full set of
        pivots)?

      \begin{itemize}\color{foreground}
         \item Every pivot \aset{must be nonzero}. If there is a zero on one of
           the pivots, then it indicates that one of the columns is a linear
           combination of one or more of the other columns.
      \end{itemize}

      \item[6.] Find \( \bm{E}^2 \) and \( \bm{E}^8 \) and \( \bm{E}^{-1} \) if
      \[%%%%%%%%%%%
      \bm{E} = \begin{bmatrix}
        1 & 0 \\
        6 & 1
      \end{bmatrix}
      \]%%%%%%%%%%%
      \linkpy{matrices}
      \fg{\[%%%%%%%%%%
          \bm{E}^2 = \begin{bmatrix}
            1 & 0 \\
            36 & 1
          \end{bmatrix}\quad
          \bm{E}^8 =
          \begin{bmatrix}
            1 & 0 \\
            1679616 & 1
          \end{bmatrix}\quad
          \bm{E}^{-1} =
          \begin{bmatrix}
            1 & 0 \\
            -6 & 1
          \end{bmatrix}
      \]}%%%%%%%%%%

      \item[7.] Find the products \tbm{FGH} and \tbm{HGF} if (with upper
        triangular zeros omitted)
        \[%%%%%%%%%%
        \bm{F} = \begin{bmatrix}
          1 &  &  \\
          2 & 1 &  \\
          0 & 0 & 1 \\
          0 & 0 & 0 & 1
        \end{bmatrix}
        \bm{G} = \begin{bmatrix}
          1 &  &  \\
          0 & 1 &  \\
          0 & 2 & 1 \\
          0 & 0 & 0 & 1
        \end{bmatrix}
        \bm{H} = \begin{bmatrix}
          1 &  &  \\
          0 & 1 &  \\
          0 & 0 & 1 \\
          0 & 0 & 2 & 1
        \end{bmatrix}
        \]%%%%%%%%%%
      \linkpy{matrices}
       \fg{\[
         \bm{FGH} =
         \begin{bmatrix}
           1 & 0 & 0 & 0 \\
           2 & 1 & 0 & 0 \\
           0 & 2 & 1 & 0 \\
           0 & 0 & 2 & 1
         \end{bmatrix} \quad
         \bm{HGF} =
         \begin{bmatrix}
           1 & 0 & 0 & 0 \\
           2 & 1 & 0 & 0 \\
           4 & 2 & 1 & 0 \\
           8 & 4 & 2 & 1
         \end{bmatrix} \quad
       \]}

       \newpage
      \item[14.] 14. Write down all six of the \( 3\times 3 \) permutation matrices,
        including \(\bm{P} = \bm{I}\). Identify their inverses, which are also
        permutation matrices. The inverses satisfy \(\bm{PP}^{-1} = \bm{I}\)
        and are on the same list.
        \fg{\begin{align*}
          \bm{P} =
          \begin{bmatrix}
            \aset{1} & 0 & 0 \\
            0 & \aset{1} & 0 \\
            0 & 0 & \aset{1}
          \end{bmatrix} \qquad
          \bm{P}^{-1} =
          \begin{bmatrix}
            \aset{1} & 0 & 0 \\
            0 & \aset{1} & 0 \\
            0 & 0 & \aset{1}
          \end{bmatrix} \\
          \bm{P} =
          \begin{bmatrix}
            0 & 0 & \aset{1} \\
            0 & \aset{1} & 0 \\
            \aset{1} & 0 & 0
          \end{bmatrix} \qquad
          \bm{P}^{-1} =
          \begin{bmatrix}
            0 & 0 & \aset{1} \\
            0 & \aset{1} & 0 \\
            \aset{1} & 0 & 0
          \end{bmatrix} \\
          \bm{P} =
          \begin{bmatrix}
            \aset{1} & 0 & 0 \\
            0 & 0 & \aset{1} \\
            0 & \aset{1} & 0
          \end{bmatrix} \qquad
          \bm{P}^{-1} =
          \begin{bmatrix}
            \aset{1} & 0 & 0 \\
            0 & 0 & \aset{1} \\
            0 & \aset{1} & 0
          \end{bmatrix} \\
          \bm{P} =
          \begin{bmatrix}
            0 & 0 & \aset{1} \\
            \aset{1} & 0 & 0 \\
            0 & \aset{1} & 0
          \end{bmatrix} \qquad
          \bm{P}^{-1} =
          \begin{bmatrix}
            0 & \aset{1} & 0 \\
            0 & 0 & \aset{1} \\
            \aset{1} & 0 & 0
          \end{bmatrix} \\
          \bm{P} =
          \begin{bmatrix}
            0 & \aset{1} & 0  \\
            \aset{1} & 0 & 0 \\
            0 & 0 & \aset{1}
          \end{bmatrix} \qquad
          \bm{P}^{-1} =
          \begin{bmatrix}
            0 & \aset{1} & 0  \\
            \aset{1} & 0 & 0 \\
            0 & 0 & \aset{1}
          \end{bmatrix} \\
          \bm{P} =
          \begin{bmatrix}
            0 & \aset{1} & 0 \\
            0 & 0 & \aset{1} \\
            \aset{1} & 0 & 0
          \end{bmatrix} \qquad
          \bm{P}^{-1} =
          \begin{bmatrix}
            0 & 0 & \aset{1} \\
            \aset{1} & 0 & 0 \\
            0 & \aset{1} & 0
          \end{bmatrix}
        \end{align*}}

      \item[18.] Decide whether the following systems are singular or
        nonsingular, and whether they have no solution, one solution, or
        infinitely many solutions:
        \[%%%%%%%%%%
        \begin{bmatrix}[ccc|c]
          0 & 1 & -1 & 2 \\
          1 & -1 & 0 & 2 \\
          1 & 0 & -1 & 2
        \end{bmatrix} \qquad
        \begin{bmatrix}[ccc|c]
          0 & 1 & -1 & 0 \\
          1 & -1 & 0 & 0 \\
          1 & 0 & -1 & 0
        \end{bmatrix} \qquad
        \begin{bmatrix}[ccc|c]
          0 & 1 & 1 & 1 \\
          1 & 1 & 0 & 1 \\
          1 & 0 & 1 & 1
        \end{bmatrix}
        \]%%%%%%%%%%
      \linkpy{matrices}

      \begin{itemize}\color{foreground}
        \item Performing rref on above martices yields:
          \begin{itemize}
            \item Singular --- no solution

            \item Singular --- \(\infty\) solutions.

            \item Nonsingular --- one solution \([0.5~0.5~0.5]\)
          \end{itemize}
      \end{itemize}

    \end{itemize}

    \newpage
    \subsection{Problems 26, 28}
    \begin{enumerate}\color{foreground-2}
      \item[26.] Which number \(c\) leads to zero in the second pivot position? A row
        exchange is needed and \(\bm{A} = \bm{LU}\) is not possible. Which
        \(c\) produces zero in the third pivot position? Then a  row exchange
        can't help and elimination fails.
        \[%%%%%%%%%%
        \bm{A} =
        \begin{bmatrix}
        1 & c & 0 \\
        2 & 4 & 1 \\
        3 & 5 & 1
        \end{bmatrix}
        \]%%%%%%%%%%
        \begin{itemize}\color{foreground}
          \item If \aset{\(c = 2\)} then row 2 would have a 0 in the pivot, yielding:
            \[%%%%%%%%%%
              \begin{bmatrix}
                1 & \aset{2} & 0 \\
                0 & 0 & 1 \\
                3 & 5 & 1
              \end{bmatrix}
            \]%%%%%%%%%%

          \item If \aset{\(c = 1\)}, then you could take the matrix down to the
            following form,
            \[%%%%%%%%%%
              \begin{bmatrix}
                1 & \aset{1} & 0 \\
                0 & 2 & 1 \\
                0 & 0 & 0
              \end{bmatrix}
            \]%%%%%%%%%%
            which would yield a singular matrix with infinite solutions.
        \end{itemize}

      \item[28.] \tbm{A} and \tbm{B} are symmetric across the diagonal (because
        4 = 4). Find their triple factorizations \tbm{LU} and say how \tbm{U}
        is related to \tbm{L} for these symmetric matrices:
        \[%%%%%%%%%%
        \bm{A} = \begin{bmatrix}
        2 & 4 \\
        4 & 11
        \end{bmatrix} \quad and \quad
        \bm{B} =
        \begin{bmatrix}
        1 & 4 & 0 \\
        4 & 12 & 4 \\
        0 & 4 & 0
        \end{bmatrix}
        \]%%%%%%%%%%
        \fg{\begin{align*}
            \bm{U}_A &= \begin{bmatrix}
              \aset{2} & 4 \\
              0 & \aset{3}
            \end{bmatrix}, \qquad
            \bm{U}_B =
            \begin{bmatrix}
              \aset{1} & 4 & 0 \\
              0 & \aset{-4}& 4 \\
              0 & 0 & \aset{-4}
            \end{bmatrix} \\
              \bm{V}_A &= \begin{bmatrix}
              1 & 2 \\
              0 & 1
            \end{bmatrix}, \qquad
            \bm{V}_B =
            \begin{bmatrix}
              1 & 4 & 0 \\
              0 & 1 & -1 \\
              0 & 0 & 1
            \end{bmatrix} \\
              \bm{L}_A &= \begin{bmatrix}
              1 & 0 \\
              2 & 1
            \end{bmatrix}, \qquad
            \bm{L}_B =
            \begin{bmatrix}
              1 & 0 & 0 \\
              4 & 1 & 0 \\
              0 & -1 & 1
            \end{bmatrix}
        \end{align*}}
      \begin{itemize}\color{foreground}
      \item {\(\bm{A}, \bm{B} = \bm{L\aset{D}V} \then \bm{L} = \bm{V}^T\)}; the
        diagonal of the upper matrix, if reduced to 1's in the pivot positions,
        yields the transponse of the lower triangular matrix.
      \end{itemize}


    \end{enumerate}

    \subsection{Problems 33, 43}\color{foreground-2}
    \begin{itemize}
      \item[33.] Solve \(\bm{Lc} = \bm{b}\) to find \tbm{c}. Then solve \(\bm{Ux} =
        \bm{c}\) to find \tbm{x}. What was \tbm{A}?
        \[%%%%%%%%%%
        \bm{L} = \begin{bmatrix}
        1 & 0 & 0 \\
        1 & 1 & 0 \\
        1 & 1 & 1
        \end{bmatrix}\quad and \quad
        \bm{U} = \begin{bmatrix}
        1 & 1 & 1 \\
        0 & 1 & 1 \\
        0 & 0 & 1
        \end{bmatrix} \quad and \quad
        \bm{b} = \begin{bmatrix} 4 \\ 5 \\ 6 \end{bmatrix}
        \]%%%%%%%%%%
      \linkpy{matrices}
      \fg{\begin{align*}
        \bm{c} = \begin{bmatrix} 4 \\ 1 \\ 1 \end{bmatrix} \quad
        \bm{x} = \begin{bmatrix} 3 \\ 0 \\ 1 \end{bmatrix} \then
        \bm{A} = \bm{LU} =
        \begin{bmatrix}
          1 & 1 & 1 \\
          1 & 2 & 2 \\
          1 & 2 & 3
        \end{bmatrix}
      \end{align*}}

      \item[43.] (Try this question) Which permutation makes \tbm{PA} upper
        triangular? Which permutations make \(\bm{P_1AP_2}\) lower triangular?
        Multiplying \tbm{A} on the right by \tbm{P_2} exchanges the \aset{columns}
        of \tbm{A}.
        \begin{align*}
        \bm{A} =
          \begin{bmatrix}
            0 & 0 & 6 \\
            1 & 2 & 3 \\
            0 & 4 & 5
          \end{bmatrix}
        \end{align*}
        \fg{\begin{align*}
            \bm{U} =
          \begin{bmatrix}
            0 & \aset{1} & 0 \\
            0 & 0 & \aset{1} \\
            \aset{1} & 0 & 0
          \end{bmatrix}
          \begin{bmatrix}
            0 & 0 & 6 \\
            1 & 2 & 3 \\
            0 & 4 & 5
          \end{bmatrix} \\
          \bm{L} =
          \begin{bmatrix}
            \aset{1} & 0 & 0 \\
            0 & 0 & \aset{1} \\
            0 & \aset{1} & 0
          \end{bmatrix}
          \begin{bmatrix}
            0 & 0 & 6 \\
            1 & 2 & 3 \\
            0 & 4 & 5
          \end{bmatrix}
          \begin{bmatrix}
            0 & 0 & \aset{1} \\
            0 & \aset{1} & 0 \\
            \aset{1} & 0 & 0
          \end{bmatrix}
        \end{align*}}

    \end{itemize}

\end{itemize}

\section{1.6 Inverses and Transposes}
\begin{itemize}
  \item []

    \subsection{Problems 3, 12, 18}
    \begin{itemize}\color{foreground-2}
      \item[3.] From \(\bm{AB} = \bm{C}\) find a formula for \(\bm{A}^{-1}\). Also
        find \(\bm{A}^{-1}\) from \(\bm{PA} = \bm{LU}\).
        \fg{\begin{align*}
            \bm{AB} &= \bm{C} \\
            \bm{A} &= \bm{CB}^{-1} \\
            \bm{A}^{-1} &= \bm{BC}^{-1} \\
            \bm{PA} &= \bm{LU}  \\
            \bm{A} &= \bm{P}^{-1}\bm{LU}  \\
            \bm{A}^{-1} &= \bm{U}^{-1}\bm{L}^{-1}\bm{P}
        \end{align*}}

      \item[12.] If \tbm{A} is invertible, which properties of A remain true
        for \(\bm{A}^{-1}\)?
        \begin{enumerate}[label=(\alph*)]
          \item \tbm{A} is triangular. \true{true}
          \item \tbm{A} is symmetric. \true{true}
          \item \tbm{A} is tridiagonal. \false{false}
          \item All entries are whole \false{false}
          \item All entire are fractions (including numbers like \( \tfrac{3}{1} \)). \true{true};
        \end{enumerate}

      \item[18.] Under what conditions on their entries are \tbm{A} and \tbm{B}
        invertible?
        \[%%%%%%%%%%
          \bm{A} =
          \begin{bmatrix}
            a & b & c \\
            d & e & 0 \\
            f & 0 & 0
          \end{bmatrix} \qquad
          \bm{B} =
          \begin{bmatrix}
            a & b & 0 \\
            c & d & 0 \\
            0 & 0 & e
          \end{bmatrix}
        \]%%%%%%%%%%
      \linkpy{matrices}
      \fg{\begin{align*}
          \rref{
            \begin{bmatrix}[ccc|ccc]
              a & b & c & 1 & 0 & 0\\
              d & e & 0 & 0 & 1 & 0\\
              f & 0 & 0 & 0 & 0 & 1
          \end{bmatrix}} &\to
          \begin{bmatrix}[ccc|ccc]
          1 & 0 & 0 & 0 & 0 & f^{-1} \\
          0 & 1 & 0 & 0 & e^{-1} & -\frac{d}{ef} \\
          0 & 0 & 1 & c^{-1} & -\frac{b}{ce} & \frac{-ae + bd}{cef}
        \end{bmatrix} \\
          \rref{
            \begin{bmatrix}[ccc|ccc]
              a & b & 0 & 1 & 0 & 0\\
              c & d & 0 & 0 & 1 & 0\\
              0 & 0 & e & 0 & 0 & 1
          \end{bmatrix}} &\to
          \begin{bmatrix}[ccc|ccc]
            1 & 0 & 0 & \frac{d}{ad - bc} & -\frac{b}{ad - bc} & 0 \\
            0 & 1 & 0 & -\frac{c}{ad - bc} & \frac{a}{ad - bc} & 0 \\
            0 & 0 & 1 & 0 & 0 & 1
        \end{bmatrix}
      \end{align*}}
      \begin{itemize}\color{foreground}
        \item \(\bm{A} \to \bm{A}^{-1} \iff c,e,f \neq 0\)
        \item \(\bm{B} \to \bm{B}^{-1} \iff e \neq 0 \land ad \neq bc\)
      \end{itemize}

  \end{itemize}
  \vspace{24pt}

  \subsection{Problems 21, 28, 41, 56, 58}
  \begin{enumerate}\color{foreground-2}
    \item[21.] (Remarkable) If \tbm{A} and \tbm{B} are square matrices, show
      that \(\bm{I}-\bm{BA}\) is invertible if \(\bm{I}-\bm{AB}\) is
      invertible. Sart from \(\bm{B}(\bm{I} - \bm{AB}) = (\bm{I} - \bm{BA})\bm{B}\)
      \fg{\begin{align*}
          \bm{B}(\bm{I} - \bm{AB}) &= (\bm{I} - \bm{BA})\bm{B} \\
          (\bm{I} - \bm{AB}) &= \bm{B}^{-1}(\bm{I} - \bm{BA})\bm{B} \\
          (\bm{I} - \bm{AB})^{-1} &= \bm{B}(\bm{I} - \bm{BA})^{-1}\bm{B}^{-1}
      \end{align*}}
      \vspace{-24pt}
      \begin{itemize}\color{foreground}
        \item Thus, as long as \(\bm{I} - \bm{BA}\) is invertible, then the
          inverse is defined.
      \end{itemize}

    \item[28.] If the product \(\bm{M} = \bm{ABC}\) of three square matrices is invertible, then
        \(\bm{A}, \bm{B}, \bm{C}\) are invertible. Find a formula for \(
        \bm{B}^{-1} \) that involves \( \bm{M}^{-1} \) and \tbm{A} and \tbm{C}.
        \fg{\begin{align*}
            \bm{M} &= \bm{ABC}  \\
            \bm{M}^{-1} &= \bm{C}^{-1}\bm{B}^{-1}\bm{A}^{-1} \\
            \bm{C}\bm{M}^{-1} &= \bm{B}^{-1}\bm{A}^{-1} \\
            \bm{C}\bm{M}^{-1}\bm{A} &= \bm{B}^{-1}
        \end{align*}}
        \vspace{-16pt}

      \item[41.] For which three numbers \(c\) is this matrix not invertible, and why
        not?
        \[%%%%%%%%%%
          \bm{A} =
          \begin{bmatrix}
            2 & c & c \\
            c & c & c \\
            8 & 7 & c
          \end{bmatrix}
        \]%%%%%%%%%%
        \begin{itemize}\color{foreground}
          \item If \(c = 0\), then there would be multile unavoidable zeros in
            the pivots.
          \item If \( c = 2\), then row 2 would just be duplicate of row 1.
          \item If \( c = 7\), then column 2 and 3 would be equal.
        \end{itemize}

      \item[57.] If \(\bm{A} = \bm{A}^T\) needs a row exchange, then it also needs a
        column exchange to stay symmetric. In matrix language, \tbm{PA} loses the
        symmetry of \tbm{A} but \aset{\tbm{PAP^T}} recovers the symmetry.

      \item[58.] \( \downarrow \)
         \begin{enumerate}
           \item How many entries of \tbm{A} can be chosen independently, if \(
             \bm{A} = \bm{A}^T \) is \( 5 \times 5 \)?
             \begin{itemize}
               \item 25 total choices \(-\) 10 under the diagonal = \aset{15}

             \end{itemize}

           \item How do \tbm{L} and \tbm{D} \( (5 \times 5) \) give the same
             number of choice in \( \bm{LDL}^T \)?
             \begin{itemize}\color{foreground}
               \item Oh, I kind of used this to find (a). Well,
                 the diagonal doesn't matter (\(\neq 0\)), since a transponse
                 can simply be thought of a rotation around the diagonal
                 elements. But, every element must match \(\bm{U}\), thus only
                 the 10 choices below matter, yieldng 15 total choices.
             \end{itemize}

        \end{enumerate}

    \end{enumerate}

\end{itemize}
