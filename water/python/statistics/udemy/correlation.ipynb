{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COURSE: Master statistics and machine learning: Intuition, Math, code\n",
    "##### COURSE URL: udemy.com/course/statsml_x/?couponCode=202006 \n",
    "## SECTION: Correlation\n",
    "### VIDEO: Correlation coefficient\n",
    "#### TEACHER: Mike X Cohen, sincxpress.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## simulate data\n",
    "\n",
    "N = 66\n",
    "\n",
    "# generate correlated data\n",
    "x = np.random.randn(N)\n",
    "y = x + np.random.randn(N)\n",
    "\n",
    "# plot the data\n",
    "plt.plot(x,y,'kp',markerfacecolor='b',markersize=12)\n",
    "plt.xlabel('Variable X')\n",
    "plt.ylabel('Variable Y')\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## compute covariance\n",
    "\n",
    "# precompute the means\n",
    "meanX = np.mean(x)\n",
    "meanY = np.mean(y)\n",
    "\n",
    "### the loop method\n",
    "covar1 = 0\n",
    "for i in range(N):\n",
    "    covar1 = covar1 + (x[i]-meanX)*(y[i]-meanY)\n",
    "    \n",
    "\n",
    "# and now for the normalization\n",
    "covar1 = covar1/(N-1)\n",
    "\n",
    "### the linear algebra method\n",
    "xCent = x-meanX\n",
    "yCent = y-meanY\n",
    "covar2 = np.dot(xCent,yCent) / (N-1)\n",
    "\n",
    "### the Python method\n",
    "covar3 = np.cov(np.vstack((x,y)))\n",
    "\n",
    "print(covar1,covar2,covar3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## now for correlation\n",
    "\n",
    "### the long method\n",
    "corr_num = sum( (x-meanX) * (y-meanY) )\n",
    "corr_den = sum((x-meanX)**2) * sum((y-meanY)**2)\n",
    "corr1 = corr_num/np.sqrt(corr_den)\n",
    "\n",
    "\n",
    "### the Python method\n",
    "corr2 = np.corrcoef(np.vstack((x,y)))\n",
    "\n",
    "print(corr1,corr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## correlation as normalized covariance\n",
    "\n",
    "xn = stats.zscore(x,ddof=1)\n",
    "yn = stats.zscore(y)\n",
    "\n",
    "corr3 = np.dot(xn,yn) / (N-1)\n",
    "\n",
    "print(corr3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2D t-value space based on r and n\n",
    "\n",
    "# define parameters\n",
    "r = np.linspace(-1,1,248)\n",
    "n = np.round( np.linspace(5,200,73) )\n",
    "\n",
    "# initialize t-value matrix\n",
    "tmatrix = np.zeros((len(r),len(n)))\n",
    "pmatrix = np.zeros((len(r),len(n)))\n",
    "\n",
    "for ri in range(len(r)):\n",
    "    for ni in range(len(n)):\n",
    "        \n",
    "        # the t-value, split into num/den\n",
    "        num = r[ri]*np.sqrt(n[ni]-2)\n",
    "        den = 1-r[ri]**2\n",
    "        \n",
    "        tmatrix[ri,ni] = num/den\n",
    "        pmatrix[ri,ni] = 1-stats.t.cdf(abs(num/den),n[ni]-2)\n",
    "\n",
    "        \n",
    "        \n",
    "# Soooo curious to see it!\n",
    "plt.imshow(tmatrix,vmin=-3,vmax=3,extent=[n[0],n[-1],r[0],r[-1]],aspect='auto',origin='lower')\n",
    "plt.contour(pmatrix<.05,1,colors='k',extent=[n[0],n[-1],r[0],r[-1]])\n",
    "plt.xlabel('Sample size')\n",
    "plt.ylabel('Correlation coefficient')\n",
    "plt.title('T-values from different r-n combos')\n",
    "plt.show()\n",
    "\n",
    "# question: Why the warning message?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final note on statistical significance\n",
    "\n",
    "r,p = stats.pearsonr(x,y)\n",
    "print(r,p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COURSE: Master statistics and machine learning: Intuition, Math, code\n",
    "##### COURSE URL: udemy.com/course/statsml_x/?couponCode=202006 \n",
    "## SECTION: Correlation\n",
    "### VIDEO: Correlation matrix\n",
    "#### TEACHER: Mike X Cohen, sincxpress.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy.matlib as matlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## simulate data\n",
    "\n",
    "# simulation parameters\n",
    "N = 1000  # time points\n",
    "M =   20  # channels\n",
    "\n",
    "# time vector (radian units)\n",
    "t = np.linspace(0,6*np.pi,N)\n",
    "\n",
    "# relationship across channels (imposing covariance)\n",
    "chanrel = np.sin(np.linspace(0,2*np.pi,M))\n",
    "\n",
    "# create the data\n",
    "data = np.zeros((M,N))\n",
    "for mi in range(M):\n",
    "    data[mi:] = np.sin(t) * chanrel[mi]\n",
    "\n",
    "data = data + np.random.randn(M,N)\n",
    "    \n",
    "\n",
    "# two ways of visualizing the multichannel data\n",
    "for i in range(M):\n",
    "    plt.plot(t,data[i,:]+i*4)\n",
    "    \n",
    "plt.yticks([])\n",
    "plt.xlabel('Time (a.u.)')\n",
    "plt.ylabel('Channel')\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(data,aspect='auto',vmin=-2,vmax=2,extent=[t[0],t[-1],0,M])\n",
    "plt.xlabel('Time (a.u.)')\n",
    "plt.ylabel('Channel')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## now compute the covariance matrix\n",
    "\n",
    "# note the size of the output!\n",
    "dataCovMat = np.cov(data.T)\n",
    "\n",
    "plt.imshow(dataCovMat,vmin=-.5,vmax=.5)\n",
    "plt.title('Data covariance matrix')\n",
    "plt.xlabel('??')\n",
    "plt.ylabel('??')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## and now the correlation matrix\n",
    "\n",
    "# note the size of the output!\n",
    "dataCorrMat = np.corrcoef(data)\n",
    "\n",
    "plt.imshow(dataCorrMat,vmin=-.5,vmax=.5)\n",
    "plt.title('Data correlation matrix')\n",
    "plt.xlabel('??')\n",
    "plt.ylabel('??')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COURSE: Master statistics and machine learning: Intuition, Math, code\n",
    "##### COURSE URL: udemy.com/course/statsml_x/?couponCode=202006 \n",
    "## SECTION: Correlation\n",
    "### VIDEO: Cosine similarity\n",
    "#### TEACHER: Mike X Cohen, sincxpress.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# range of requested correlation coefficients\n",
    "rs = np.linspace(-1,1,100)\n",
    "\n",
    "# sample size\n",
    "N = 500\n",
    "\n",
    "\n",
    "# initialize output matrix\n",
    "corrs = np.zeros((len(rs),2))\n",
    "\n",
    "\n",
    "# loop over a range of r values\n",
    "for ri in range(len(rs)):\n",
    "    \n",
    "    # generate data\n",
    "    x = np.random.randn(N)\n",
    "    y = x*rs[ri] + np.random.randn(N)*np.sqrt(1-rs[ri]**2)\n",
    "    \n",
    "    # optional mean-off-centering\n",
    "    #x = x+10\n",
    "    #y = y+10\n",
    "    \n",
    "    \n",
    "    # compute correlation\n",
    "    corrs[ri,0] = np.corrcoef(x,y)[0,1]\n",
    "    \n",
    "    # compute cosine similarity\n",
    "    cs_num = sum(x*y)\n",
    "    cs_den = np.sqrt(sum(x*x)) * np.sqrt(sum(y*y))\n",
    "    corrs[ri,1] = cs_num / cs_den\n",
    "    \n",
    "    # using built-in distance function\n",
    "    #corrs[ri,1] = 1-spatial.distance.cosine(x,y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## visualize the results\n",
    "\n",
    "plt.plot(rs,corrs[:,0],'s-',label='Correlation')\n",
    "plt.plot(rs,corrs[:,1],'s-',label='Cosine sim.')\n",
    "plt.legend()\n",
    "plt.xlabel('Requested correlation')\n",
    "plt.ylabel('Empirical correlation')\n",
    "plt.axis('square')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(corrs[:,0],corrs[:,1],'ks')\n",
    "plt.axis('square')\n",
    "plt.xlabel('Correlation')\n",
    "plt.ylabel('Cosine similarity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# their empirical correlation\n",
    "np.corrcoef(corrs.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COURSE: Master statistics and machine learning: Intuition, Math, code\n",
    "##### COURSE URL: udemy.com/course/statsml_x/?couponCode=202006 \n",
    "## SECTION: Correlation\n",
    "### VIDEO: Simulate data with specified correlation\n",
    "#### TEACHER: Mike X Cohen, sincxpress.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## simulate data\n",
    "\n",
    "# data simulation parameters\n",
    "N = 100  # number of samples\n",
    "r = .6   # desired correlation coefficient\n",
    "\n",
    "# start with random numbers\n",
    "x = np.random.randn(N)\n",
    "y = np.random.randn(N)\n",
    "\n",
    "# impose the correlation on y\n",
    "y = x*r + y*np.sqrt(1-r**2)\n",
    "\n",
    "# plot the data\n",
    "plt.plot(x,y,'kp',markerfacecolor='b',markersize=12)\n",
    "plt.xlabel('Variable X')\n",
    "plt.ylabel('Variable Y')\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## compute the empirical correlation\n",
    "\n",
    "empR = np.corrcoef(x,y)\n",
    "\n",
    "print('Desired r=%g, empirical r=%g'%(r,empR[0,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test the errors as a function of N\n",
    "\n",
    "# range of sample sizes\n",
    "Ns = np.round( np.linspace(5,400,123) ).astype(int)\n",
    "\n",
    "# theoretical correlation coefficient (fixed)\n",
    "r = .6\n",
    "\n",
    "# initialize\n",
    "corrs = np.zeros(len(Ns))\n",
    "\n",
    "# run the experiment!\n",
    "for ni in range(len(Ns)):\n",
    "    x = np.random.randn(Ns[ni])\n",
    "    y = x*r + np.random.randn(Ns[ni])*np.sqrt(1-r**2)\n",
    "    corrs[ni] = (r-np.corrcoef(x,y)[0,1])**2\n",
    "    \n",
    "\n",
    "plt.stem(Ns,corrs,'ko-')\n",
    "plt.xlabel('Sample size')\n",
    "plt.ylabel('Squared divergence')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COURSE: Master statistics and machine learning: Intuition, Math, code\n",
    "##### COURSE URL: udemy.com/course/statsml_x/?couponCode=202006 \n",
    "## SECTION: Correlation\n",
    "### VIDEO: Kendall correlation\n",
    "#### TEACHER: Mike X Cohen, sincxpress.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## generate some data!\n",
    "\n",
    "N = 40\n",
    "\n",
    "# movie ratings\n",
    "docuRatings = np.random.randint(low=1,high=6,size=N)\n",
    "\n",
    "# education level (1-4, correlated with docuRatings)\n",
    "eduLevel = np.ceil( (docuRatings + np.random.randint(low=1,high=5,size=N) )/9 * 4 )\n",
    "\n",
    "# compute the correlations\n",
    "cr = [0,0,0]\n",
    "cr[0] = stats.kendalltau(eduLevel,docuRatings)[0]\n",
    "cr[1] = stats.pearsonr(eduLevel,docuRatings)[0]\n",
    "cr[2] = stats.spearmanr(eduLevel,docuRatings)[0]\n",
    "\n",
    "# round for convenience\n",
    "cr = np.round(cr,4)\n",
    "\n",
    "\n",
    "# plot the data\n",
    "plt.plot(eduLevel+np.random.randn(N)/30,docuRatings+np.random.randn(N)/30,'ks',markersize=10,markerfacecolor=[0,0,0,.25])\n",
    "plt.xticks(np.arange(4)+1)\n",
    "plt.yticks(np.arange(5)+1)\n",
    "plt.xlabel('Education level')\n",
    "plt.ylabel('Documentary ratings')\n",
    "plt.grid()\n",
    "plt.title('$r_k$ = %g, $r_p$=%g, $r_s$=%g'%(cr[0],cr[1],cr[2]))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## correlation estimation errors under H0\n",
    "\n",
    "numExprs = 1000\n",
    "nValues = 50\n",
    "nCategories = 6\n",
    "\n",
    "c = np.zeros((numExprs,3))\n",
    "\n",
    "for i in range(numExprs):\n",
    "    \n",
    "    # create data\n",
    "    x = np.random.randint(low=0,high=nCategories,size=nValues)\n",
    "    y = np.random.randint(low=0,high=nCategories,size=nValues)\n",
    "    \n",
    "    # store correlations\n",
    "    c[i,:] = [ stats.kendalltau(x,y)[0],\n",
    "               stats.pearsonr(x,y)[0],\n",
    "               stats.spearmanr(x,y)[0] ]\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## show the graphs\n",
    "plt.bar(range(3),np.mean(c**2,axis=0))\n",
    "plt.errorbar(range(3),np.mean(c**2,axis=0),yerr=np.std(c**2,ddof=1,axis=0))\n",
    "plt.xticks(range(3),('Kendall','Pearson','Spearman'))\n",
    "plt.ylabel('Squared correlation error')\n",
    "plt.title('Noise correlation ($r^2$) distributions')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(c[:100,:],'s-')\n",
    "plt.xlabel('Experiment number')\n",
    "plt.ylabel('Correlation value')\n",
    "plt.legend(('K','P','S'))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.imshow(np.corrcoef(c.T),vmin=.9,vmax=1)\n",
    "plt.xticks(range(3),['K','P','S'])\n",
    "plt.yticks(range(3),('K','P','S'))\n",
    "plt.colorbar()\n",
    "plt.title('Correlation matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COURSE: Master statistics and machine learning: Intuition, Math, code\n",
    "##### COURSE URL: udemy.com/course/statsml_x/?couponCode=202006 \n",
    "## SECTION: Correlation\n",
    "### VIDEO: Partial correlations\n",
    "#### TEACHER: Mike X Cohen, sincxpress.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm using pingouin for partial correlations.\n",
    "# You might need to install it, e.g., using the line below.\n",
    "# This needs to be run only once per install.\n",
    "# conda install -c conda-forge pingouin\n",
    "import pingouin as pg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## the example from the video\n",
    "\n",
    "# raw correlations\n",
    "rmg = .7\n",
    "rsg = .8\n",
    "rms = .9\n",
    "\n",
    "# partial correlations\n",
    "rho_mg_s = (rmg - rsg*rms) / ( np.sqrt(1-rsg**2)*np.sqrt(1-rms**2) )\n",
    "rho_sg_m = (rsg - rmg*rms) / ( np.sqrt(1-rmg**2)*np.sqrt(1-rms**2) )\n",
    "\n",
    "print(rho_mg_s)\n",
    "print(rho_sg_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## now for datasets\n",
    "\n",
    "N = 76\n",
    "\n",
    "# correlated datasets\n",
    "x1 = np.linspace(1,10,N) + np.random.randn(N)\n",
    "x2 = x1 + np.random.randn(N)\n",
    "x3 = x1 + np.random.randn(N)\n",
    "\n",
    "# let's convert these data to a pandas frame\n",
    "df = pd.DataFrame()\n",
    "df['x1'] = x1\n",
    "df['x2'] = x2\n",
    "df['x3'] = x3\n",
    "\n",
    "# compute the \"raw\" correlation matrix\n",
    "cormatR = df.corr()\n",
    "print(cormatR)\n",
    "\n",
    "# print out one value\n",
    "print(' ')\n",
    "print(cormatR.values[1,0])\n",
    "\n",
    "# partial correlation\n",
    "pc = pg.partial_corr(df,x='x3',y='x2',covar='x1')\n",
    "print(' ')\n",
    "print(pc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## visualize the matrices\n",
    "\n",
    "fig,ax = plt.subplots(1,2,figsize=(6,3))\n",
    "\n",
    "# raw correlations\n",
    "ax[0].imshow(cormatR.values,vmin=-1,vmax=1)\n",
    "ax[0].set_xticks(range(3))\n",
    "ax[0].set_yticks(range(3))\n",
    "\n",
    "# add text \n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        ax[0].text(i,j,np.round(cormatR.values[i,j],2), horizontalalignment='center')\n",
    "\n",
    "        \n",
    "        \n",
    "# partial correlations\n",
    "partialCorMat = df.pcorr()\n",
    "ax[1].imshow(partialCorMat.values,vmin=-1,vmax=1)\n",
    "ax[1].set_xticks(range(3))\n",
    "ax[1].set_yticks(range(3))\n",
    "\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        ax[1].text(i,j,np.round(partialCorMat.values[i,j],2), horizontalalignment='center')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COURSE: Master statistics and machine learning: Intuition, Math, code\n",
    "##### COURSE URL: udemy.com/course/statsml_x/?couponCode=202006 \n",
    "## SECTION: Correlation\n",
    "### VIDEO: Spearman correlation and Fisher-Z\n",
    "#### TEACHER: Mike X Cohen, sincxpress.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Anscobe's quartet\n",
    "\n",
    "anscombe = np.array([\n",
    "     # series 1     series 2      series 3       series 4\n",
    "    [10,  8.04,    10,  9.14,    10,  7.46,      8,  6.58, ],\n",
    "    [ 8,  6.95,     8,  8.14,     8,  6.77,      8,  5.76, ],\n",
    "    [13,  7.58,    13,  8.76,    13, 12.74,      8,  7.71, ],\n",
    "    [ 9,  8.81,     9,  8.77,     9,  7.11,      8,  8.84, ],\n",
    "    [11,  8.33,    11,  9.26,    11,  7.81,      8,  8.47, ],\n",
    "    [14,  9.96,    14,  8.10,    14,  8.84,      8,  7.04, ],\n",
    "    [ 6,  7.24,     6,  6.13,     6,  6.08,      8,  5.25, ],\n",
    "    [ 4,  4.26,     4,  3.10,     4,  5.39,      8,  5.56, ],\n",
    "    [12, 10.84,    12,  9.13,    12,  8.15,      8,  7.91, ],\n",
    "    [ 7,  4.82,     7,  7.26,     7,  6.42,      8,  6.89, ],\n",
    "    [ 5,  5.68,     5,  4.74,     5,  5.73,     19, 12.50, ]\n",
    "    ])\n",
    "\n",
    "\n",
    "# plot and compute correlations\n",
    "fig,ax = plt.subplots(2,2,figsize=(6,6))\n",
    "ax = ax.ravel()\n",
    "\n",
    "for i in range(4):\n",
    "    ax[i].plot(anscombe[:,i*2],anscombe[:,i*2+1],'ko')\n",
    "    ax[i].set_xticks([])\n",
    "    ax[i].set_yticks([])\n",
    "    corr_p = stats.pearsonr(anscombe[:,i*2],anscombe[:,i*2+1])[0]\n",
    "    corr_s = stats.spearmanr(anscombe[:,i*2],anscombe[:,i*2+1])[0]\n",
    "    ax[i].set_title('r_p = %g, r_s = %g'%(np.round(corr_p*100)/100,np.round(corr_s*100)/100))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fisher-Z transform\n",
    "\n",
    "\n",
    "# simulate correlation coefficients\n",
    "N = 10000\n",
    "r = 2*np.random.rand(N) - 1\n",
    "\n",
    "# Fisher-Z\n",
    "fz = np.arctanh(r)\n",
    "\n",
    "\n",
    "\n",
    "# overlay the Fisher-Z\n",
    "y,x = np.histogram(fz,30)\n",
    "x = (x[1:]+x[0:-1])/2\n",
    "plt.bar(x,y)\n",
    "\n",
    "# raw correlations\n",
    "y,x = np.histogram(r,30)\n",
    "x = (x[1:]+x[0:-1])/2\n",
    "plt.bar(x,y)\n",
    "\n",
    "\n",
    "plt.xlabel('r / f')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(('Fisher-Z','Raw r'))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(N),np.sort(r), 'o',markerfacecolor='w',markersize=7)\n",
    "plt.plot(range(N),np.sort(fz),'o',markerfacecolor='w',markersize=7)\n",
    "plt.ylabel('Value')\n",
    "plt.legend(('Correlation','Fisher-Z'))\n",
    "\n",
    "# zoom in\n",
    "plt.ylim([-.8,.8])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COURSE: Master statistics and machine learning: Intuition, Math, code\n",
    "##### COURSE URL: udemy.com/course/statsml_x/?couponCode=202006 \n",
    "## SECTION: Correlation\n",
    "### VIDEO: The subgroups correlation paradox\n",
    "#### TEACHER: Mike X Cohen, sincxpress.com\n",
    "\n",
    "##### note: official called \"Simpson's paradox\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializations\n",
    "n = 20 # sample points per group\n",
    "offsets = [2, 3.5, 5] # mean offsets\n",
    "\n",
    "allx = np.array([])\n",
    "ally = np.array([])\n",
    "\n",
    "c = 'rbk' # dot colors\n",
    "\n",
    "# generate and plot data\n",
    "for datai in range(3):\n",
    "    \n",
    "    # generate data\n",
    "    x = np.linspace(offsets[datai]-1,offsets[datai]+1,n)\n",
    "    y = np.mean(x) + np.random.randn(n)/2\n",
    "    \n",
    "    # subgroup correlation\n",
    "    r,p = pearsonr(x,y)\n",
    "    \n",
    "    # plot\n",
    "    plt.plot(x,y,'o',color=c[datai],label=f'r={r:.3f}, p={p:.3f}')\n",
    "    \n",
    "    # gather the data into one array\n",
    "    allx = np.append(allx,x)\n",
    "    ally = np.append(ally,y)\n",
    "    \n",
    "\n",
    "\n",
    "# % now correlate the groups\n",
    "[r,p] = pearsonr(allx,ally)\n",
    "plt.title(f'r={r:.4f}, p={p:.4f}')\n",
    "\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
