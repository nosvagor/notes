{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COURSE: Master statistics and machine learning: Intuition, Math, code\n",
    "##### COURSE URL: udemy.com/course/statsml_x/?couponCode=202006 \n",
    "## SECTION: Clustering and dimension-reduction\n",
    "### VIDEO: dbscan\n",
    "#### TEACHER: Mike X Cohen, sincxpress.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create data\n",
    "\n",
    "nPerClust = 50\n",
    "\n",
    "# blur around centroid (std units)\n",
    "blur = .5\n",
    "\n",
    "# XY centroid locations\n",
    "A = [  1, 1 ]\n",
    "B = [ -3, 1 ]\n",
    "C = [  3, 3 ]\n",
    "\n",
    "# generate data\n",
    "a = [ A[0]+np.random.randn(nPerClust)*blur , A[1]+np.random.randn(nPerClust)*blur ]\n",
    "b = [ B[0]+np.random.randn(nPerClust)*blur , B[1]+np.random.randn(nPerClust)*blur ]\n",
    "c = [ C[0]+np.random.randn(nPerClust)*blur , C[1]+np.random.randn(nPerClust)*blur ]\n",
    "\n",
    "# concatanate into a list\n",
    "data = np.transpose( np.concatenate((a,b,c),axis=1) )\n",
    "\n",
    "# show the data\n",
    "fig,ax = plt.subplots(1,2,figsize=(10,10))\n",
    "ax[0].plot(data[:,0],data[:,1],'s')\n",
    "ax[0].set_title('How we see the data')\n",
    "ax[0].axis('square')\n",
    "\n",
    "\n",
    "### distance matrix\n",
    "D = np.zeros((len(data),len(data)))\n",
    "for i in range(len(D)):\n",
    "    for j in range(len(D)):\n",
    "        D[i,j] = np.sqrt( (data[i,0]-data[j,0])**2 + (data[i,1]-data[j,1])**2 )\n",
    "\n",
    "ax[1].imshow(D)\n",
    "ax[1].set_title('How dbscan sees the data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## dbscan\n",
    "\n",
    "clustmodel = DBSCAN(eps=.6,min_samples=6).fit(data)\n",
    "groupidx = clustmodel.labels_\n",
    "\n",
    "# number of clusters\n",
    "nclust = max(groupidx)+1 # +1 for indexing\n",
    "\n",
    "# compute cluster centers\n",
    "cents = np.zeros((nclust,2))\n",
    "for ci in range(nclust):\n",
    "    cents[ci,0] = np.mean(data[groupidx==ci,0])\n",
    "    cents[ci,1] = np.mean(data[groupidx==ci,1])\n",
    "print(cents)\n",
    "\n",
    "# draw lines from each data point to the centroids of each cluster\n",
    "lineColors = 'rkbgmrkbgmrkbgmrkbgmrkbgmrkbgmrkbgmrkbgmrkbgmrkbgmrkbgmrkbgm'\n",
    "for i in range(len(data)):\n",
    "    if groupidx[i]==-1:\n",
    "        plt.plot(data[i,0],data[i,1],'k+')\n",
    "    else:\n",
    "        plt.plot([ data[i,0], cents[groupidx[i],0] ],[ data[i,1], cents[groupidx[i],1] ],lineColors[groupidx[i]])\n",
    "        \n",
    "\n",
    "# now draw the raw data in different colors\n",
    "for i in range(nclust):\n",
    "    plt.plot(data[groupidx==i,0],data[groupidx==i,1],'o',markerfacecolor=lineColors[i])\n",
    "\n",
    "# and now plot the centroid locations\n",
    "plt.plot(cents[:,0],cents[:,1],'ko',markerfacecolor='g',markersize=10)\n",
    "plt.title('Result of dbscan clustering (k=' + str(nclust) + ')')\n",
    "\n",
    "# finally, the \"ground-truth\" centers\n",
    "plt.plot(A[0],A[1],'kp',markersize=20,markerfacecolor='y')\n",
    "plt.plot(B[0],B[1],'kp',markersize=20,markerfacecolor='y')\n",
    "plt.plot(C[0],C[1],'kp',markersize=20,markerfacecolor='y')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## testing the parameter space\n",
    "\n",
    "# parameter ranges\n",
    "epsilons = np.linspace(.1,2,40)\n",
    "minpoints = np.arange(1,31)\n",
    "\n",
    "# initialize results matrix\n",
    "results = np.zeros((len(epsilons),len(minpoints),2))\n",
    "\n",
    "for ei in range(len(epsilons)):\n",
    "    for di in range(len(minpoints)):\n",
    "        clustmodel = DBSCAN(eps=epsilons[ei],min_samples=minpoints[di]).fit(data)\n",
    "        groupidx = clustmodel.labels_\n",
    "        results[ei,di,0] = max(groupidx)\n",
    "        results[ei,di,1] = sum(groupidx==-1)\n",
    "\n",
    "\n",
    "\n",
    "# for colormap discretization\n",
    "from pylab import cm\n",
    "\n",
    "fig,ax = plt.subplots(1,2,figsize=(10,4))\n",
    "aa = ax[0].imshow(results[:,:,0],vmin=0,vmax=5,\n",
    "                  extent=[minpoints[0],minpoints[-1],epsilons[0],epsilons[-1]],\n",
    "                  aspect=20,origin='lower',cmap=cm.get_cmap('jet',10))\n",
    "ax[0].set_xlabel('Minimum points')\n",
    "ax[0].set_ylabel('Epsilon')\n",
    "ax[0].set_title('Number of groups')\n",
    "plt.colorbar(aa,ax=ax[0])\n",
    "\n",
    "aa = ax[1].imshow(results[:,:,1],vmin=1,vmax=len(data)/3,\n",
    "                  extent=[minpoints[0],minpoints[-1],epsilons[0],epsilons[-1]],\n",
    "                  aspect=20,origin='lower',cmap=cm.get_cmap('jet',10))\n",
    "ax[1].set_xlabel('Minimum points')\n",
    "ax[1].set_ylabel('Epsilon')\n",
    "ax[1].set_title('Number of \"noise\" points')\n",
    "plt.colorbar(aa,ax=ax[1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## determining the appropriate parameters\n",
    "\n",
    "# NOTE: The thesis I linked in the video is no longer available. \n",
    "#    There are several methods to determine an appropriate epsilon\n",
    "#    parameter, depending on the nature of the data and level of\n",
    "#    sophistication required. I hope the references below are helpful; you\n",
    "#    can also google around to find more tips for picking parameters.\n",
    "# \n",
    "# https://towardsdatascience.com/machine-learning-clustering-dbscan-determine-the-optimal-value-for-epsilon-eps-python-example-3100091cfbc\n",
    "# https://core.ac.uk/download/pdf/219373759.pdf\n",
    "# https://www.biorxiv.org/content/10.1101/2020.07.09.195784v2.full.pdf\n",
    " \n",
    "\n",
    "D = np.zeros(len(data))\n",
    "\n",
    "for i in range(len(data)):\n",
    "    # compute distance\n",
    "    d = np.sqrt( (data[i,0]-data[:,0])**2 + (data[i,1]-data[:,1])**2 )\n",
    "    \n",
    "    # distance to 3rd closest point\n",
    "    d = np.sort(d)\n",
    "    D[i] = d[2]\n",
    "    \n",
    "plt.plot(np.sort(D),'s-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Try again with nonlinear clusters\n",
    "\n",
    "N = 1000\n",
    "th = np.linspace(0,2*np.pi,N)\n",
    "\n",
    "# create the two circles\n",
    "data1 = np.array((np.cos(th), np.sin(th))) + np.random.randn(2,N)/15\n",
    "data2 = .3*np.array((np.cos(th), np.sin(th))) + np.random.randn(2,N)/15\n",
    "\n",
    "# put them together into one dataset\n",
    "circdata = np.hstack((data1,data2)).T\n",
    "print(np.shape(circdata))\n",
    "\n",
    "# plot\n",
    "plt.plot(circdata[:,0],circdata[:,1],'ko')\n",
    "plt.axis('square')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## dbscan\n",
    "\n",
    "clustmodel = DBSCAN(eps=.2,min_samples=6).fit(circdata)\n",
    "groupidx = clustmodel.labels_\n",
    "\n",
    "nclust = max(groupidx)+1 # +1 for indexing\n",
    "\n",
    "# now draw the raw data in different colors\n",
    "for i in range(nclust):\n",
    "    plt.plot(circdata[groupidx==i,0],circdata[groupidx==i,1],'o',color=lineColors[i],markerfacecolor='w')\n",
    "\n",
    "# and plot unassigned data\n",
    "plt.plot(circdata[groupidx==-1,0],circdata[groupidx==-1,1],'k+')\n",
    "plt.axis('square')\n",
    "plt.title('Result of dbscan clustering (k=' + str(nclust) + ')')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COURSE: Master statistics and machine learning: Intuition, Math, code\n",
    "##### COURSE URL: udemy.com/course/statsml_x/?couponCode=202006 \n",
    "## SECTION: Clustering and dimension-reduction\n",
    "### VIDEO: ICA\n",
    "#### TEACHER: Mike X Cohen, sincxpress.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import FastICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create the data\n",
    "\n",
    "#number of data points\n",
    "N = 1000\n",
    "\n",
    "#a non-Gaussian distribution\n",
    "dist1 = np.random.rand(N)\n",
    "\n",
    "# another non-Gaussian distribution\n",
    "dist2 = np.random.rand(N)**4\n",
    "\n",
    "\n",
    "# setup the figure\n",
    "fig = plt.figure(constrained_layout=False,figsize=(10,8))\n",
    "axs = fig.add_gridspec(2,2)\n",
    "\n",
    "\n",
    "# individual distributions\n",
    "ax1 = fig.add_subplot(axs[0,0])\n",
    "ax1.hist(dist1,100)\n",
    "ax1.set_title('Distribution 1')\n",
    "\n",
    "ax2 = fig.add_subplot(axs[0,1])\n",
    "ax2.hist(dist2,100)\n",
    "ax2.set_title('Distribution 2')\n",
    "\n",
    "# and their summed histogram\n",
    "ax3 = fig.add_subplot(axs[1,:])\n",
    "ax3.hist(dist1+dist2,100)\n",
    "ax3.set_title('Distributions 1+2')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ICA\n",
    "\n",
    "# two non-Gaussian distributions\n",
    "data = np.vstack((.4*dist1+.3*dist2, .8*dist1-.7*dist2))\n",
    "\n",
    "# ICA and scores\n",
    "fastica = FastICA(max_iter=10000,tol=.0000001)\n",
    "b = fastica.fit_transform(data)\n",
    "iscores = b@data\n",
    "\n",
    "\n",
    "# plot distributions\n",
    "\n",
    "# IC 1\n",
    "fig,ax = plt.subplots(1,2,figsize=(8,5))\n",
    "ax[0].hist(iscores[0,:],100)\n",
    "ax[0].set_title('IC 1')\n",
    "\n",
    "# IC 2\n",
    "ax[1].hist(iscores[1,:],100)\n",
    "ax[1].set_title('IC 2')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## look at the data in data space and IC space\n",
    "\n",
    "fig,ax = plt.subplots(1,2,figsize=(8,5))\n",
    "\n",
    "ax[0].plot(data[0,:],data[1,:],'o')\n",
    "ax[0].set_title('Data space')\n",
    "\n",
    "ax[1].plot(iscores[0,:],iscores[1,:],'o')\n",
    "ax[1].set_title('IC space')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## show that the original data match the ICs\n",
    "\n",
    "# now plot data as a function of ICs\n",
    "fig,ax = plt.subplots(1,2,figsize=(8,5))\n",
    "\n",
    "ax[0].plot(dist1,iscores[0,:],'o')\n",
    "ax[0].set_xticks([])\n",
    "ax[0].set_yticks([])\n",
    "ax[0].set_xlabel('Original signal')\n",
    "ax[0].set_ylabel('IC1 scores')\n",
    "\n",
    "ax[1].plot(dist2,iscores[1,:],'o')\n",
    "ax[1].set_xticks([])\n",
    "ax[1].set_yticks([])\n",
    "ax[1].set_xlabel('Original signal')\n",
    "ax[1].set_ylabel('IC2 scores')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COURSE: Master statistics and machine learning: Intuition, Math, code\n",
    "##### COURSE URL: udemy.com/course/statsml_x/?couponCode=202006 \n",
    "## SECTION: Clustering and dimension-reduction\n",
    "### VIDEO: K-means clustering\n",
    "#### TEACHER: Mike X Cohen, sincxpress.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "from scipy import stats\n",
    "from sklearn.cluster import KMeans\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create data\n",
    "\n",
    "nPerClust = 50\n",
    "\n",
    "# blur around centroid (std units)\n",
    "blur = 1\n",
    "\n",
    "# XY centroid locations\n",
    "A = [  1, 1 ]\n",
    "B = [ -3, 1 ]\n",
    "C = [  3, 3 ]\n",
    "\n",
    "# generate data\n",
    "a = [ A[0]+np.random.randn(nPerClust)*blur , A[1]+np.random.randn(nPerClust)*blur ]\n",
    "b = [ B[0]+np.random.randn(nPerClust)*blur , B[1]+np.random.randn(nPerClust)*blur ]\n",
    "c = [ C[0]+np.random.randn(nPerClust)*blur , C[1]+np.random.randn(nPerClust)*blur ]\n",
    "\n",
    "# concatanate into a list\n",
    "data = np.transpose( np.concatenate((a,b,c),axis=1) )\n",
    "\n",
    "# show the data\n",
    "plt.plot(data[:,0],data[:,1],'s')\n",
    "plt.title('How k-means sees the data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## k-means clustering\n",
    "\n",
    "k = 3 # how many clusters?\n",
    "kmeans = KMeans(n_clusters=k)\n",
    "kmeans = kmeans.fit(data)\n",
    "# group labels\n",
    "groupidx = kmeans.predict(data)\n",
    "# centroids\n",
    "cents = kmeans.cluster_centers_\n",
    "\n",
    "# draw lines from each data point to the centroids of each cluster\n",
    "lineColors = 'rgbgmrkbgm';\n",
    "for i in range(0,len(data)):\n",
    "    plt.plot([ data[i,0],cents[groupidx[i],0] ],[ data[i,1],cents[groupidx[i],1] ],lineColors[groupidx[i]])\n",
    "\n",
    "# and now plot the centroid locations\n",
    "plt.plot(cents[:,0],cents[:,1],'ko')\n",
    "\n",
    "# finally, the \"ground-truth\" centers\n",
    "plt.plot(A[0],A[1],'mp')\n",
    "plt.plot(B[0],B[1],'mp')\n",
    "plt.plot(C[0],C[1],'mp')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## determining the appropriate number of clusters (qualitative)\n",
    "\n",
    "fig,ax = plt.subplots(2,3,figsize=(7,5))\n",
    "ax = ax.flatten()\n",
    "\n",
    "for k in range(6):\n",
    "    \n",
    "    kmeans = KMeans(n_clusters=k+1).fit(data)\n",
    "    groupidx = kmeans.predict(data)\n",
    "    cents = kmeans.cluster_centers_\n",
    "    \n",
    "    # draw lines from each data point to the centroids of each cluster\n",
    "    for i in range(0,len(data)):\n",
    "        ax[k].plot([ data[i,0],cents[groupidx[i],0] ],[ data[i,1],cents[groupidx[i],1] ],lineColors[groupidx[i]])\n",
    "    \n",
    "    # and now plot the centroid locations\n",
    "    ax[k].plot(cents[:,0],cents[:,1],'ko')\n",
    "    ax[k].set_xticks([])\n",
    "    ax[k].set_yticks([])\n",
    "    ax[k].set_title('%g clusters'%(k+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## number of clusters (quantative)\n",
    "\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "\n",
    "ssds = np.zeros(7)\n",
    "sils = np.zeros(7)/0\n",
    "\n",
    "for k in range(7):\n",
    "    kmeans = KMeans(n_clusters=k+1).fit(data)\n",
    "    ssds[k] = np.mean(kmeans.inertia_)\n",
    "    \n",
    "    if k>0:\n",
    "        s = silhouette_samples(data,kmeans.predict(data))\n",
    "        sils[k] = np.mean( s )\n",
    "\n",
    "plt.plot(np.arange(1,8),ssds,'k^-',markerfacecolor='k')\n",
    "plt.title('The elbow test')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(np.arange(1,8),sils,'k^-',markerfacecolor='k')\n",
    "plt.title('The silhouette test')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Try again in 3D\n",
    "\n",
    "nPerClust = 50\n",
    "\n",
    "# blur around centroid (std units)\n",
    "n = 1\n",
    "\n",
    "# XY centroid locations\n",
    "A = [  1, 2,  0 ]\n",
    "B = [ -2, 1, -2 ]\n",
    "C = [  3, 3,  2 ]\n",
    "\n",
    "# generate data\n",
    "a = [ A[0]+np.random.randn(nPerClust)*n , A[1]+np.random.randn(nPerClust)*n , A[2]+np.random.randn(nPerClust)*n ]\n",
    "b = [ B[0]+np.random.randn(nPerClust)*n , B[1]+np.random.randn(nPerClust)*n , B[2]+np.random.randn(nPerClust)*n ]\n",
    "c = [ C[0]+np.random.randn(nPerClust)*n , C[1]+np.random.randn(nPerClust)*n , C[2]+np.random.randn(nPerClust)*n ]\n",
    "\n",
    "# concatanate into a list\n",
    "data = np.transpose( np.concatenate((a,b,c),axis=1) )\n",
    "\n",
    "# show the data\n",
    "ax = Axes3D(plt.figure())\n",
    "ax.scatter(data[:,0],data[:,1],data[:,2], c = 'b', marker='o')\n",
    "plt.title('How k-means sees the data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "k = 3 # how many clusters?\n",
    "kmeans = KMeans(n_clusters=k)\n",
    "kmeans = kmeans.fit(data)\n",
    "# group labels\n",
    "groupidx = kmeans.predict(data)\n",
    "# centroids\n",
    "cents = kmeans.cluster_centers_\n",
    "\n",
    "# draw lines from each data point to the centroids of each cluster\n",
    "lineColors = 'rgbgmrkbgm';\n",
    "ax = Axes3D(plt.figure())\n",
    "for i in range(0,len(data)):\n",
    "    ax.plot([ data[i,0],cents[groupidx[i],0] ],[ data[i,1],cents[groupidx[i],1] ],[ data[i,2],cents[groupidx[i],2] ],lineColors[groupidx[i]])\n",
    "\n",
    "# and now plot the centroid locations\n",
    "ax.plot(cents[:,0],cents[:,1],cents[:,2],'ko')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COURSE: Master statistics and machine learning: Intuition, Math, code\n",
    "##### COURSE URL: udemy.com/course/statsml_x/?couponCode=202006 \n",
    "## SECTION: Clustering and dimension-reduction\n",
    "### VIDEO: K-nearest neighbor\n",
    "#### TEACHER: Mike X Cohen, sincxpress.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create data\n",
    "\n",
    "nPerClust = 50\n",
    "\n",
    "# XY centroid locations\n",
    "A = [  1, 0 ]\n",
    "B = [ -1, 0 ]\n",
    "\n",
    "# generate data\n",
    "a = [ A[0]+np.random.randn(nPerClust) , A[1]+np.random.randn(nPerClust) ]\n",
    "b = [ B[0]+np.random.randn(nPerClust) , B[1]+np.random.randn(nPerClust) ]\n",
    "\n",
    "# concatanate into a list\n",
    "data = np.transpose( np.concatenate((a,b),axis=1) )\n",
    "grouplabels = np.concatenate((np.zeros(nPerClust),np.ones(nPerClust)))\n",
    "\n",
    "# group color assignment\n",
    "groupcolors = 'br'\n",
    "\n",
    "# show the data\n",
    "fig,ax = plt.subplots(1)\n",
    "ax.plot(data[grouplabels==0,0],data[grouplabels==0,1],'ks',markerfacecolor=groupcolors[0])\n",
    "ax.plot(data[grouplabels==1,0],data[grouplabels==1,1],'ks',markerfacecolor=groupcolors[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## compute distance matrix\n",
    "\n",
    "# initialize\n",
    "distmat = np.zeros((nPerClust*2,nPerClust*2))\n",
    "\n",
    "# loop over elements\n",
    "for i in range(nPerClust*2):\n",
    "    for j in range(nPerClust*2):\n",
    "        distmat[i,j] = np.sqrt( (data[i,0]-data[j,0])**2 + (data[i,1]-data[j,1])**2 )\n",
    "\n",
    "plt.imshow(distmat,vmax=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create the new data point\n",
    "\n",
    "# random new point\n",
    "newpoint = 2*np.random.rand(2)-1\n",
    "\n",
    "# and plot it\n",
    "ax.plot(newpoint[0],newpoint[1],'ko',MarkerFaceColor='g',markersize=15)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute distance vector\n",
    "distvec = np.zeros(nPerClust*2)\n",
    "\n",
    "for i in range(nPerClust*2):\n",
    "    distvec[i] = np.sqrt( (data[i,0]-newpoint[0])**2 + (data[i,1]-newpoint[1])**2 )\n",
    "    \n",
    "\n",
    "# show the distances\n",
    "plt.plot(distvec,'s',markerfacecolor='k')\n",
    "plt.xlabel('Data element index')\n",
    "plt.ylabel('Distance to new point')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## now for the labeling\n",
    "\n",
    "# k parameter\n",
    "k = 3\n",
    "\n",
    "# sort the distances\n",
    "sortidx = np.argsort(distvec)\n",
    "\n",
    "# find the group assignment of the nearest neighbors\n",
    "print(grouplabels[sortidx[:k]])\n",
    "whichgroup = int( np.median(grouplabels[sortidx[:k]]) )\n",
    "print('New data belong to group ' + str(whichgroup))\n",
    "\n",
    "# and re-plot\n",
    "ax.plot(newpoint[0],newpoint[1],'ko',MarkerFaceColor='g',markersize=15)\n",
    "ax.plot(newpoint[0],newpoint[1],'ko',MarkerFaceColor=groupcolors[whichgroup])\n",
    "ax.plot(data[sortidx[:k],0],data[sortidx[:k],1],'ko',markersize=10,fillstyle='none')\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## now using Python functions\n",
    "knn = KNeighborsClassifier(n_neighbors=k, metric='euclidean')\n",
    "knn.fit(data,grouplabels)\n",
    "\n",
    "whichgroupP = knn.predict(newpoint.reshape(1,-1))\n",
    "\n",
    "print('New data belong to group ' + str(whichgroupP[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COURSE: Master statistics and machine learning: Intuition, Math, code\n",
    "##### COURSE URL: udemy.com/course/statsml_x/?couponCode=202006 \n",
    "## SECTION: Clustering and dimension-reduction\n",
    "### VIDEO: PCA\n",
    "#### TEACHER: Mike X Cohen, sincxpress.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create the data\n",
    "\n",
    "N = 1000\n",
    "\n",
    "# data\n",
    "x = np.array([ np.random.randn(N), .4*np.random.randn(N) ]).T\n",
    "\n",
    "# rotation matrix\n",
    "th = np.pi/4\n",
    "R1 = [ [np.cos(th), -np.sin(th)], [np.sin(th), np.cos(th)] ]\n",
    "\n",
    "# rotate data\n",
    "y = x@np.array(R1)\n",
    "\n",
    "axlim = [-1.1*max(abs(y.flatten())), 1.1*max(abs(y.flatten()))] # axis limits\n",
    "\n",
    "# and plot\n",
    "plt.plot(y[:,0],y[:,1],'k.')\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.xlabel('$X_1$')\n",
    "plt.ylabel('$X_2$')\n",
    "plt.axis('square')\n",
    "plt.title('Data space')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## now for PCA\n",
    "\n",
    "# PCA using scikitlearn's function\n",
    "pca = PCA().fit(y)\n",
    "\n",
    "# get the PC scores\n",
    "pcscores = pca.transform(y)\n",
    "\n",
    "\n",
    "# and plot\n",
    "fig,ax = plt.subplots(1,2,figsize=(8,4))\n",
    "ax[0].plot(y[:,0],y[:,1],'k.')\n",
    "ax[0].axis('square')\n",
    "ax[0].set_xticks([])\n",
    "ax[0].set_yticks([])\n",
    "ax[1].set_xlim(axlim)\n",
    "ax[1].set_ylim(axlim)\n",
    "ax[0].set_xlabel('$X_1$')\n",
    "ax[0].set_ylabel('$X_2$')\n",
    "ax[0].set_title('Data space')\n",
    "\n",
    "ax[1].plot(pcscores[:,0],pcscores[:,1],'k.')\n",
    "ax[1].axis('square')\n",
    "ax[1].set_xticks([])\n",
    "ax[1].set_yticks([])\n",
    "ax[1].set_xlim(axlim)\n",
    "ax[1].set_ylim(axlim)\n",
    "ax[1].set_xlabel('$PC_1$')\n",
    "ax[1].set_ylabel('$PC_2$')\n",
    "ax[1].set_title('PC space')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for dimension reduction\n",
    "\n",
    "spikes = np.loadtxt('spikes.csv',delimiter=',')\n",
    "\n",
    "\n",
    "# let's see it!\n",
    "plt.plot(np.mean(spikes,axis=0))\n",
    "plt.title('Average of all spikes')\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(spikes,aspect='auto')\n",
    "plt.xlabel('Time points')\n",
    "plt.ylabel('Individual spikes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## pca\n",
    "\n",
    "# PCA using scikitlearn's function\n",
    "pca = PCA().fit(spikes)\n",
    "\n",
    "# get the PC scores and the eigenspectrum\n",
    "pcscores = pca.transform(spikes)\n",
    "explVar = pca.explained_variance_\n",
    "explVar = 100*explVar/sum(explVar) # convert to %total\n",
    "coeffs  = pca.components_\n",
    "\n",
    "\n",
    "# show the scree plot (a.k.a. eigenspectrum)\n",
    "fig,ax = plt.subplots(1,2,figsize=(10,4))\n",
    "\n",
    "ax[0].plot(explVar,'kp-',markerfacecolor='k',markersize=10)\n",
    "ax[0].set_xlabel('Component number')\n",
    "ax[0].set_ylabel('Percent variance explained')\n",
    "\n",
    "ax[1].plot(np.cumsum(explVar),'kp-',markerfacecolor='k',markersize=10)\n",
    "ax[1].set_xlabel('Component number')\n",
    "ax[1].set_ylabel('Cumulative percent variance explained')\n",
    "plt.show()\n",
    "\n",
    "# now show the PC weights for the top two components\n",
    "plt.plot(coeffs[0,:])\n",
    "plt.plot(coeffs[1,:])\n",
    "plt.xlabel('Time')\n",
    "plt.legend(('Comp 1','Comp 2'))\n",
    "plt.title('PC weights (coefficients)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## finally, show the PC scores\n",
    "plt.plot(pcscores[:,0],pcscores[:,1],'k.',markersize=.1)\n",
    "plt.xlabel('PC_1')\n",
    "plt.ylabel('PC_2')\n",
    "plt.title('PC space')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
