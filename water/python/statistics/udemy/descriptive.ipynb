{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COURSE: Master statistics and machine learning: Intuition, Math, code\n",
    "##### COURSE URL: udemy.com/course/statsml_x/?couponCode=202006 \n",
    "## SECTION: Descriptive statistics\n",
    "### VIDEO: Computing central tendency\n",
    "#### TEACHER: Mike X Cohen, sincxpress.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create some data distributions\n",
    "\n",
    "# the distributions\n",
    "N = 10001   # number of data points\n",
    "nbins = 30  # number of histogram bins\n",
    "\n",
    "d1 = np.random.randn(N) - 1\n",
    "d2 = 3*np.random.randn(N)\n",
    "d3 = np.random.randn(N) + 1\n",
    "\n",
    "# need their histograms\n",
    "y1,x1 = np.histogram(d1,nbins)\n",
    "x1 = (x1[1:]+x1[:-1])/2\n",
    "\n",
    "y2,x2 = np.histogram(d2,nbins)\n",
    "x2 = (x2[1:]+x2[:-1])/2\n",
    "\n",
    "y3,x3 = np.histogram(d3,nbins)\n",
    "x3 = (x3[1:]+x3[:-1])/2\n",
    "\n",
    "\n",
    "# plot them\n",
    "plt.plot(x1,y1,'b')\n",
    "plt.plot(x2,y2,'r')\n",
    "plt.plot(x3,y3,'k')\n",
    "\n",
    "plt.xlabel('Data values')\n",
    "plt.ylabel('Data counts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## overlay the mean\n",
    "\n",
    "# compute the means\n",
    "mean_d1 = sum(d1) / len(d1)\n",
    "mean_d2 = np.mean(d2)\n",
    "mean_d3 = np.mean(d3)\n",
    "\n",
    "# plot them\n",
    "plt.plot(x1,y1,'b', x2,y2,'r', x3,y3,'k')\n",
    "plt.plot([mean_d1,mean_d1],[0,max(y1)],'b--')\n",
    "plt.plot([mean_d2,mean_d2],[0,max(y2)],'r--')\n",
    "plt.plot([mean_d3,mean_d3],[0,max(y3)],'k--')\n",
    "\n",
    "plt.xlabel('Data values')\n",
    "plt.ylabel('Data counts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## \"failure\" of the mean\n",
    "\n",
    "# new dataset of distribution combinations\n",
    "d4 = np.hstack( (np.random.randn(N)-2,np.random.randn(N)+2) )\n",
    "# and its histogram\n",
    "[y4,x4] = np.histogram(d4,nbins)\n",
    "x4 = (x4[:-1]+x4[1:])/2\n",
    "\n",
    "# and its mean\n",
    "mean_d4 = np.mean(d4)\n",
    "\n",
    "\n",
    "plt.plot(x4,y4,'b')\n",
    "plt.plot([mean_d4,mean_d4],[0,max(y4)],'b--')\n",
    "\n",
    "plt.xlabel('Data values')\n",
    "plt.ylabel('Data counts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## median\n",
    "\n",
    "# create a log-normal distribution\n",
    "shift   = 0\n",
    "stretch = .7\n",
    "n       = 2000\n",
    "nbins   = 50\n",
    "\n",
    "# generate data\n",
    "data = stretch*np.random.randn(n) + shift\n",
    "data = np.exp( data )\n",
    "\n",
    "# and its histogram\n",
    "y,x = np.histogram(data,nbins)\n",
    "x = (x[:-1]+x[1:])/2\n",
    "\n",
    "# compute mean and median\n",
    "datamean = np.mean(data)\n",
    "datamedian = np.median(data)\n",
    "\n",
    "\n",
    "# plot data\n",
    "fig,ax = plt.subplots(2,1,figsize=(4,6))\n",
    "ax[0].plot(data,'.',color=[.5,.5,.5],label='Data')\n",
    "ax[0].plot([1,n],[datamean,datamean],'r--',label='Mean')\n",
    "ax[0].plot([1,n],[datamedian,datamedian],'b--',label='Median')\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].plot(x,y)\n",
    "ax[1].plot([datamean,datamean],[0,max(y)],'r--')\n",
    "ax[1].plot([datamedian,datamedian],[0,max(y)],'b--')\n",
    "ax[1].set_title('Log-normal data histogram')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## mode\n",
    "\n",
    "data = np.round(np.random.randn(10))\n",
    "\n",
    "uniq_data = np.unique(data)\n",
    "for i in range(len(uniq_data)):\n",
    "    print(f'{uniq_data[i]} appears {sum(data==uniq_data[i])} times.')\n",
    "\n",
    "print(' ')\n",
    "print('The modal value is %g'%stats.mode(data)[0][0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COURSE: Master statistics and machine learning: Intuition, Math, code\n",
    "##### COURSE URL: udemy.com/course/statsml_x/?couponCode=202006 \n",
    "## SECTION: Descriptive statistics\n",
    "### VIDEO: Computing dispersion\n",
    "#### TEACHER: Mike X Cohen, sincxpress.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create some data distributions\n",
    "\n",
    "# the distributions\n",
    "N = 10001   # number of data points\n",
    "nbins = 30  # number of histogram bins\n",
    "\n",
    "d1 = np.random.randn(N) - 1\n",
    "d2 = 3*np.random.randn(N)\n",
    "d3 = np.random.randn(N) + 1\n",
    "\n",
    "# need their histograms\n",
    "y1,x1 = np.histogram(d1,nbins)\n",
    "x1 = (x1[1:]+x1[:-1])/2\n",
    "\n",
    "y2,x2 = np.histogram(d2,nbins)\n",
    "x2 = (x2[1:]+x2[:-1])/2\n",
    "\n",
    "y3,x3 = np.histogram(d3,nbins)\n",
    "x3 = (x3[1:]+x3[:-1])/2\n",
    "\n",
    "\n",
    "# plot them\n",
    "plt.plot(x1,y1,'b')\n",
    "plt.plot(x2,y2,'r')\n",
    "plt.plot(x3,y3,'k')\n",
    "\n",
    "plt.xlabel('Data values')\n",
    "plt.ylabel('Data counts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# side note:\n",
    "\n",
    "meanval = 10.2\n",
    "stdval  = 7.5\n",
    "numsamp = 123\n",
    "\n",
    "# this\n",
    "np.random.normal(meanval,stdval,numsamp)\n",
    "\n",
    "# is equivalent to\n",
    "np.random.randn(numsamp)*stdval + meanval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## overlay the mean\n",
    "\n",
    "# compute the means\n",
    "mean_d1 = sum(d1) / len(d1)\n",
    "mean_d2 = np.mean(d2)\n",
    "mean_d3 = np.mean(d3)\n",
    "\n",
    "# plot them\n",
    "plt.plot(x1,y1,'b', x2,y2,'r', x3,y3,'k')\n",
    "plt.plot([mean_d1,mean_d1],[0,max(y1)],'b--')\n",
    "plt.plot([mean_d2,mean_d2],[0,max(y2)],'r--')\n",
    "plt.plot([mean_d3,mean_d3],[0,max(y3)],'k--')\n",
    "\n",
    "plt.xlabel('Data values')\n",
    "plt.ylabel('Data counts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## now for the standard deviation\n",
    "\n",
    "# initialize\n",
    "stds = np.zeros(3)\n",
    "\n",
    "# compute standard deviations\n",
    "stds[0] = np.std(d1,ddof=1)\n",
    "stds[1] = np.std(d2,ddof=1)\n",
    "stds[2] = np.std(d3,ddof=1)\n",
    "\n",
    "\n",
    "# same plot as earlier\n",
    "plt.plot(x1,y1,'b', x2,y2,'r', x3,y3,'k')\n",
    "plt.plot([mean_d1,mean_d1],[0,max(y1)],'b--', [mean_d2,mean_d2],[0,max(y2)],'r--',[mean_d3,mean_d3],[0,max(y3)],'k--')\n",
    "\n",
    "# now add stds\n",
    "plt.plot([mean_d1-stds[0],mean_d1+stds[0]],[.4*max(y1),.4*max(y1)],'b',linewidth=10)\n",
    "plt.plot([mean_d2-stds[1],mean_d2+stds[1]],[.5*max(y2),.5*max(y2)],'r',linewidth=10)\n",
    "plt.plot([mean_d3-stds[2],mean_d3+stds[2]],[.6*max(y3),.6*max(y3)],'k',linewidth=10)\n",
    "\n",
    "plt.xlabel('Data values')\n",
    "plt.ylabel('Data counts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## different variance measures\n",
    "\n",
    "variances = np.arange(1,11)\n",
    "N = 300\n",
    "\n",
    "varmeasures = np.zeros((4,len(variances)))\n",
    "\n",
    "for i in range(len(variances)):\n",
    "    \n",
    "    # create data and mean-center\n",
    "    data = np.random.randn(N) * variances[i]\n",
    "    datacent = data - np.mean(data)\n",
    "    \n",
    "    # variance\n",
    "    varmeasures[0,i] = sum(datacent**2) / (N-1)\n",
    "    \n",
    "    # \"biased\" variance\n",
    "    varmeasures[1,i] = sum(datacent**2) / N\n",
    "    \n",
    "    # standard deviation\n",
    "    varmeasures[2,i] = np.sqrt( sum(datacent**2) / (N-1) )\n",
    "    \n",
    "    # MAD (mean absolute difference)\n",
    "    varmeasures[3,i] = sum(abs(datacent)) / (N-1)\n",
    "    \n",
    "\n",
    "# show them!\n",
    "plt.plot(variances,varmeasures.T)\n",
    "plt.legend(('Var','biased var','Std','MAD'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fano factor and coefficient of variation (CV)\n",
    "\n",
    "# need positive-valued data (why?)\n",
    "data = np.random.poisson(3,300)  # \"Poisson noise\"\n",
    "\n",
    "fig,ax = plt.subplots(2,1)\n",
    "ax[0].plot(data,'s')\n",
    "ax[0].set_title('Poisson noise')\n",
    "\n",
    "ax[1].hist(data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## compute fano factor and CV for a range of lambda parameters\n",
    "\n",
    "# list of parameters\n",
    "lambdas = np.linspace(1,12,15)\n",
    "\n",
    "# initialize output vectors\n",
    "fano = np.zeros(len(lambdas))\n",
    "cv   = np.zeros(len(lambdas))\n",
    "\n",
    "for li in range(len(lambdas)):\n",
    "    \n",
    "    # generate new data\n",
    "    data = np.random.poisson(lambdas[li],1000)\n",
    "    \n",
    "    # compute the metrics\n",
    "    cv[li]   = np.std(data) / np.mean(data) # need ddof=1 here?\n",
    "    fano[li] = np.var(data) / np.mean(data)\n",
    "\n",
    "\n",
    "# and plot\n",
    "plt.plot(lambdas,cv,'bs-')\n",
    "plt.plot(lambdas,fano,'ro-')\n",
    "plt.legend(('CV','Fano'))\n",
    "plt.xlabel('$\\lambda$')\n",
    "plt.ylabel('CV or Fano')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COURSE: Master statistics and machine learning: Intuition, Math, code\n",
    "##### COURSE URL: udemy.com/course/statsml_x/?couponCode=202006 \n",
    "## SECTION: Descriptive statistics\n",
    "### VIDEO: Data from different distributions\n",
    "#### TEACHER: Mike X Cohen, sincxpress.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "# or: from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Gaussian\n",
    "\n",
    "# number of discretizations\n",
    "N = 1001\n",
    "\n",
    "x = np.linspace(-4,4,N)\n",
    "gausdist = stats.norm.pdf(x)\n",
    "\n",
    "plt.plot(x,gausdist)\n",
    "plt.title('Analytic Gaussian (normal) distribution')\n",
    "plt.show()\n",
    "\n",
    "# is this a probability distribution?\n",
    "print(sum(gausdist))\n",
    "# try scaling by dx...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Normally-distributed random numbers\n",
    "\n",
    "# parameters\n",
    "stretch = 1 # variance (square of standard deviation)\n",
    "shift   = 5 # mean\n",
    "n       = 1000\n",
    "\n",
    "# create data\n",
    "data = stretch*np.random.randn(n) + shift\n",
    "\n",
    "# plot data\n",
    "plt.hist(data,25)\n",
    "plt.title('Empirical normal distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Uniformly-distributed numbers\n",
    "\n",
    "# parameters\n",
    "stretch = 2 # not the variance\n",
    "shift   = .5\n",
    "n       = 10000\n",
    "\n",
    "# create data\n",
    "data = stretch*np.random.rand(n) + shift-stretch/2\n",
    "\n",
    "# plot data\n",
    "fig,ax = plt.subplots(2,1,figsize=(5,6))\n",
    "\n",
    "ax[0].plot(data,'.',markersize=1)\n",
    "ax[0].set_title('Uniform data values')\n",
    "\n",
    "ax[1].hist(data,25)\n",
    "ax[1].set_title('Uniform data histogram')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## log-normal distribution\n",
    "\n",
    "N = 1001\n",
    "x = np.linspace(0,10,N)\n",
    "lognormdist = stats.lognorm.pdf(x,1)\n",
    "\n",
    "plt.plot(x,lognormdist)\n",
    "plt.title('Analytic log-normal distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## empirical log-normal distribution\n",
    "\n",
    "shift   = 5  # equal to the mean?\n",
    "stretch = .5 # equal to standard deviation?\n",
    "n = 2000     # number of data points\n",
    "\n",
    "# generate data\n",
    "data = stretch*np.random.randn(n) + shift\n",
    "data = np.exp( data )\n",
    "\n",
    "# plot data\n",
    "fig,ax = plt.subplots(2,1,figsize=(4,6))\n",
    "ax[0].plot(data,'.')\n",
    "ax[0].set_title('Log-normal data values')\n",
    "\n",
    "ax[1].hist(data,25)\n",
    "ax[1].set_title('Log-normal data histogram')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## binomial\n",
    "\n",
    "# a binomial distribution is the probability of K heads in N coin tosses,\n",
    "# given a probability of p heads (e.g., .5 is a fair coin).\n",
    "\n",
    "n = 10 # number on coin tosses\n",
    "p = .5 # probability of heads\n",
    "\n",
    "x = range(n+2)\n",
    "bindist = stats.binom.pmf(x,n,p)\n",
    "\n",
    "plt.bar(x,bindist)\n",
    "plt.title('Binomial distribution (n=%s, p=%g)'%(n,p))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## t\n",
    "\n",
    "x  = np.linspace(-4,4,1001)\n",
    "df = 200\n",
    "t  = stats.t.pdf(x,df)\n",
    "\n",
    "plt.plot(x,t)\n",
    "plt.xlabel('t-value')\n",
    "plt.ylabel('P(t | H$_0$)')\n",
    "plt.title('t(%g) distribution'%df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## F\n",
    "\n",
    "# parameters\n",
    "num_df = 5   # numerator degrees of freedom\n",
    "den_df = 100 # denominator df\n",
    "\n",
    "# values to evaluate \n",
    "x = np.linspace(0,10,10001)\n",
    "\n",
    "# the distribution\n",
    "fdist = stats.f.pdf(x,num_df,den_df)\n",
    "\n",
    "plt.plot(x,fdist)\n",
    "plt.title(f'F({num_df},{den_df}) distribution')\n",
    "plt.xlabel('F value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COURSE: Master statistics and machine learning: Intuition, Math, code\n",
    "##### COURSE URL: udemy.com/course/statsml_x/?couponCode=202006 \n",
    "## SECTION: Descriptive statistics\n",
    "### VIDEO: Entropy\n",
    "#### TEACHER: Mike X Cohen, sincxpress.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## \"discrete\" entropy\n",
    "\n",
    "# generate data\n",
    "N = 1000\n",
    "numbers = np.ceil( 8*np.random.rand(N)**2 )\n",
    "numbers[numbers==7] = 4\n",
    "plt.plot(numbers,'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## \"discrete\" entropy\n",
    "\n",
    "# generate data\n",
    "N = 1000\n",
    "numbers = np.ceil( 8*np.random.rand(N)**2 )\n",
    "\n",
    "\n",
    "# get counts and probabilities\n",
    "u = np.unique(numbers)\n",
    "probs = np.zeros(len(u))\n",
    "\n",
    "for ui in range(len(u)):\n",
    "    probs[ui] = sum(numbers==u[ui]) / N\n",
    "\n",
    "    \n",
    "# compute entropy\n",
    "entropee = -sum( probs*np.log2(probs+np.finfo(float).eps) )\n",
    "\n",
    "\n",
    "# plot\n",
    "plt.bar(u,probs)\n",
    "plt.title('Entropy = %g'%entropee)\n",
    "plt.xlabel('Data value')\n",
    "plt.ylabel('Probability')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for random variables\n",
    "\n",
    "# create Brownian noise\n",
    "N = 1123\n",
    "brownnoise = np.cumsum( np.sign(np.random.randn(N)) )\n",
    "\n",
    "fig,ax = plt.subplots(2,1,figsize=(4,6))\n",
    "ax[0].plot(brownnoise)\n",
    "ax[0].set_xlabel('Data index')\n",
    "ax[0].set_ylabel('Data value')\n",
    "ax[0].set_title('Brownian noise')\n",
    "\n",
    "ax[1].hist(brownnoise,30)\n",
    "ax[1].set_xlabel('Data value')\n",
    "ax[1].set_ylabel('Counts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### now compute entropy\n",
    "# number of bins\n",
    "nbins = 50\n",
    "\n",
    "# bin the data and convert to probability\n",
    "nPerBin,bins = np.histogram(brownnoise,nbins)\n",
    "probs = nPerBin / sum(nPerBin)\n",
    "\n",
    "# compute entropy\n",
    "entro = -sum( probs*np.log2(probs+np.finfo(float).eps) )\n",
    "\n",
    "print('Entropy = %g'%entro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COURSE: Master statistics and machine learning: Intuition, Math, code\n",
    "##### COURSE URL: udemy.com/course/statsml_x/?couponCode=202006 \n",
    "## SECTION: Descriptive statistics\n",
    "### VIDEO: Histogram bins\n",
    "#### TEACHER: Mike X Cohen, sincxpress.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create some data\n",
    "\n",
    "# number of data points\n",
    "n = 1000\n",
    "\n",
    "# number of histogram bins\n",
    "k = 40\n",
    "\n",
    "# generate log-normal distribution\n",
    "data = np.exp( np.random.randn(n)/2 )\n",
    "\n",
    "\n",
    "# one way to show a histogram\n",
    "plt.hist(data,k)\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## try the Freedman-Diaconis rule\n",
    "\n",
    "r = 2*stats.iqr(data)*n**(-1/3)\n",
    "b = np.ceil( (max(data)-min(data) )/r )\n",
    "\n",
    "plt.hist(data,int(b))\n",
    "\n",
    "# or directly from the hist function\n",
    "#plt.hist(data,bins='fd')\n",
    "\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Count')\n",
    "plt.title('F-D \"rule\" using %g bins'%b)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# small aside on Seaborn\n",
    "\n",
    "import seaborn as sns\n",
    "sns.distplot(data) # uses FD rule by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## lots of histograms with increasing bins\n",
    "\n",
    "bins2try = np.round( np.linspace(5,n/2,30) )\n",
    "\n",
    "for bini in range(len(bins2try)):\n",
    "    y,x = np.histogram(data,int(bins2try[bini]))\n",
    "    x = (x[:-1]+x[1:])/2\n",
    "    plt.plot(x,y,'.-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COURSE: Master statistics and machine learning: Intuition, Math, code\n",
    "##### COURSE URL: udemy.com/course/statsml_x/?couponCode=202006 \n",
    "## SECTION: Descriptive statistics\n",
    "### VIDEO: Inter-quartile range (IQR)\n",
    "#### TEACHER: Mike X Cohen, sincxpress.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create the data\n",
    "\n",
    "# random number data\n",
    "n = 1000\n",
    "data = np.random.randn(n)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rank-transform the data and scale to 1\n",
    "dataR = stats.rankdata(data)/n\n",
    "\n",
    "# find the values closest to 25% and 75% of the distribution\n",
    "q1 = np.argmin((dataR-.25)**2)\n",
    "q3 = np.argmin((dataR-.75)**2)\n",
    "\n",
    "# get the two values in the data\n",
    "iq_vals = data[[q1,q3]]\n",
    "\n",
    "# IQR is the difference between them\n",
    "iqrange1 = iq_vals[1] - iq_vals[0]\n",
    "\n",
    "# or use Python's built-in function ;)\n",
    "iqrange2 = stats.iqr(data)\n",
    "\n",
    "print(iqrange1,iqrange2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COURSE: Master statistics and machine learning: Intuition, Math, code\n",
    "##### COURSE URL: udemy.com/course/statsml_x/?couponCode=202006 \n",
    "## SECTION: Descriptive statistics\n",
    "### VIDEO: QQ plots\n",
    "#### TEACHER: Mike X Cohen, sincxpress.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## generate data\n",
    "\n",
    "n    = 1000\n",
    "data = np.random.randn(n)\n",
    "# data = np.exp( np.random.randn(n)*.8 ) # log-norm distribution\n",
    "\n",
    "# theoretical normal distribution given N\n",
    "x = np.linspace(-4,4,10001)\n",
    "theonorm = stats.norm.pdf(x)\n",
    "theonorm = theonorm/max(theonorm)\n",
    "\n",
    "# plot histograms on top of each other\n",
    "yy,xx = np.histogram(data,40)\n",
    "yy = yy/max(yy)\n",
    "xx = (xx[:-1]+xx[1:])/2\n",
    "\n",
    "plt.plot(xx,yy,label='Empirical')\n",
    "plt.plot(x,theonorm,label='Theoretical')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create a QQ plot\n",
    "\n",
    "zSortData  = np.sort(stats.zscore(data))\n",
    "sortNormal = stats.norm.ppf(np.linspace(0,1,n))\n",
    "\n",
    "# QQ plot is theory vs reality\n",
    "plt.plot(sortNormal,zSortData,'o')\n",
    "\n",
    "# set axes to be equal\n",
    "xL,xR = plt.xlim()\n",
    "yL,yR = plt.ylim()\n",
    "lims  = [ np.min([xL,xR,yL,yR]),np.max([xL,xR,yL,yR]) ]\n",
    "plt.xlim(lims)\n",
    "plt.ylim(lims)\n",
    "\n",
    "# draw red comparison line\n",
    "plt.plot(lims,lims)\n",
    "\n",
    "plt.xlabel('Theoretical normal')\n",
    "plt.ylabel('Observed data')\n",
    "plt.title('QQ plot')\n",
    "plt.axis('square')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Python solution\n",
    "\n",
    "x = stats.probplot(data,plot=plt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COURSE: Master statistics and machine learning: Intuition, Math, code\n",
    "##### COURSE URL: udemy.com/course/statsml_x/?couponCode=202006 \n",
    "## SECTION: Descriptive statistics\n",
    "### VIDEO: Violin plots\n",
    "#### TEACHER: Mike X Cohen, sincxpress.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create the data\n",
    "\n",
    "n = 1000\n",
    "thresh = 5 # threshold for cropping data\n",
    "\n",
    "data = np.exp( np.random.randn(n) )\n",
    "data[data>thresh] = thresh + np.random.randn(sum(data>thresh))*.1\n",
    "\n",
    "# show histogram\n",
    "plt.hist(data,30)\n",
    "plt.title('Histogram')\n",
    "plt.show()\n",
    "\n",
    "# show violin plot\n",
    "plt.violinplot(data)\n",
    "plt.title('Violin')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# another option: swarm plot\n",
    "\n",
    "import seaborn as sns\n",
    "sns.swarmplot(data,orient='v')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
